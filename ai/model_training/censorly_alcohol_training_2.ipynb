{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iezv5Z4v3YwM",
        "outputId": "d5415523-4247-450b-a7db-27d992d0c983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "%pip -q install --upgrade ultralytics==8.3.199 pillow opencv-python tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnf__TsX7iMG",
        "outputId": "0abe94ce-511b-4660-b5c7-584b577a6f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Klasörler OK ✅\n",
            "data.yaml -> /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3/data.yaml\n",
            "# binary alcohol detector (labels = binary)\n",
            "path: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3\n",
            "train: images/train\n",
            "val: images/validation\n",
            "test: images/test\n",
            "\n",
            "names:\n",
            "  0: alcohol\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os, shutil, glob\n",
        "\n",
        "# Proje kökü – senin verdiğin yapı\n",
        "BASE = Path(\"/content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3\")\n",
        "IMAGES = BASE/\"images\"            # dokunmuyoruz\n",
        "LABELS = BASE/\"labels\"            # BINARY (hepsi 0) — artık eğitim bu klasörden\n",
        "ORIG   = BASE/\"original_labels\"   # çok sınıflı yedek (dokunmuyoruz)\n",
        "\n",
        "assert IMAGES.exists(), \"images klasörü bulunamadı!\"\n",
        "assert LABELS.exists(), \"labels (binary) klasörü bulunamadı! Önce dönüştürme adımını tamamla.\"\n",
        "print(\"Klasörler OK ✅\")\n",
        "\n",
        "# 'val' veya 'validation' hangisi varsa onu kullan\n",
        "use_val = \"val\" if (IMAGES/\"val\").exists() else (\"validation\" if (IMAGES/\"validation\").exists() else None)\n",
        "assert use_val is not None, \"images altında 'val' ya da 'validation' klasörü bulunamadı!\"\n",
        "\n",
        "from pathlib import Path\n",
        "DATA_YAML = BASE/\"data.yaml\"\n",
        "DATA_YAML.write_text(f\"\"\"# binary alcohol detector (labels = binary)\n",
        "path: {BASE.as_posix()}\n",
        "train: images/train\n",
        "val: images/{use_val}\n",
        "test: images/test\n",
        "\n",
        "names:\n",
        "  0: alcohol\n",
        "\"\"\")\n",
        "print(\"data.yaml ->\", DATA_YAML)\n",
        "print(DATA_YAML.read_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdyvRIz97nY2"
      },
      "outputs": [],
      "source": [
        "# Test split (val değil)\n",
        "test_metrics = model.val(\n",
        "    data=str(DATA_YAML),\n",
        "    imgsz=IMGSZ,\n",
        "    split='test',\n",
        "    project=str(RUN_DIR),\n",
        "    name=f\"{run_name}_test\",\n",
        "    exist_ok=True\n",
        ")\n",
        "test_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfI2Yde3ssUw",
        "outputId": "e50d185f-9008-427b-8b72-5c05e239df1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "[MOUNT] Drive bağlanıyor...\n",
            "Mounted at /content/drive\n",
            "\n",
            "[CHECK] TRUE: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3\n",
            "[OK] True layout doğru.\n",
            "[CHECK] FALSE: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False\n",
            "[OK] False layout doğru.\n",
            "[COUNT train     ] pos=1782 | neg= 342\n",
            "\n",
            "[STAGE train] Tüm pozitif + mevcut tüm negatif taşınıyor (mode=symlink)\n",
            "[DONE train] +pos=1782  +neg=342\n",
            "[COUNT validation] pos= 197 | neg= 123\n",
            "\n",
            "[STAGE validation] Tüm pozitif + mevcut tüm negatif taşınıyor (mode=symlink)\n",
            "[DONE validation] +pos=197  +neg=123\n",
            "[COUNT test      ] pos= 199 | neg=  65\n",
            "\n",
            "[STAGE test] Tüm pozitif + mevcut tüm negatif taşınıyor (mode=symlink)\n",
            "[DONE test] +pos=199  +neg=65\n",
            "\n",
            "[YAML] /content/drive/MyDrive/censorly-training/alcohol/data_true_false_detect.yaml\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt': 100% ━━━━━━━━━━━━ 18.4MB 184.6MB/s 0.1s\n",
            "[MODEL] start_weights = yolo11s.pt\n",
            "\n",
            "[TRAIN] başlıyor… (task=detect, single_cls=True)\n",
            "Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/drive/MyDrive/censorly-training/alcohol/data_true_false_detect.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=70, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0015, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11s_true_false_detect_960_symlink, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/censorly-training/alcohol/runs_detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 109.2MB/s 0.0s\n",
            "Overriding class names with single class.\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "YOLO11s summary: 181 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 115.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.1±0.1 MB/s, size: 86.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/alcohol_mix/labels/train... 2124 images, 343 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2124/2124 6.5it/s 5:26\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/alcohol_mix/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=960 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA A100-SXM4-40GB) 39.56G total, 0.14G reserved, 0.11G allocated, 39.31G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     9428179       48.48         1.294         81.38          6451        (1, 3, 960, 960)                    list\n",
            "     9428179       96.97         1.973         33.33          6396        (2, 3, 960, 960)                    list\n",
            "     9428179       193.9         3.261         36.87          6800        (4, 3, 960, 960)                    list\n",
            "     9428179       387.9         5.815         38.35          5626        (8, 3, 960, 960)                    list\n",
            "     9428179       775.7        10.976         51.46          5663       (16, 3, 960, 960)                    list\n",
            "     9428179        1551        20.869         100.4          5677       (32, 3, 960, 960)                    list\n",
            "     9428179        3103        40.741         193.7          6446       (64, 3, 960, 960)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 36 for CUDA:0 23.72G/39.56G (60%) ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.2 ms, read: 35.7±8.5 MB/s, size: 70.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/alcohol_mix/labels/train.cache... 2124 images, 343 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2124/2124 3.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.1±0.1 MB/s, size: 69.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/alcohol_mix/labels/validation... 320 images, 123 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 320/320 5.9it/s 53.8s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/alcohol_mix/labels/validation.cache\n",
            "Plotting labels to /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0015, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005625000000000001), 87 bias(decay=0.0)\n",
            "Image sizes 960 train, 960 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink\u001b[0m\n",
            "Starting training for 70 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/70      21.1G      1.447      2.092      1.584        242        960: 100% ━━━━━━━━━━━━ 59/59 0.4it/s 2:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.4it/s 13.2s\n",
            "                   all        320        618      0.229      0.235      0.136     0.0563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/70      20.3G      1.557      1.812      1.685        199        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 47.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.1it/s 1.6s\n",
            "                   all        320        618      0.116     0.0906     0.0369    0.00899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/70      20.7G      1.558      1.829      1.716        169        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.8it/s 1.8s\n",
            "                   all        320        618      0.159      0.186     0.0773     0.0305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/70      20.5G      1.554      1.776      1.696        200        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.0it/s 1.7s\n",
            "                   all        320        618       0.18      0.202     0.0897     0.0311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/70      19.6G      1.507      1.731      1.673        175        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 49.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.235      0.304       0.15     0.0658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/70      20.6G      1.476      1.699      1.642        269        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.372      0.343      0.263      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/70      20.4G       1.45      1.624      1.606        162        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 54.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.1it/s 1.6s\n",
            "                   all        320        618      0.388       0.46      0.348      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/70      20.7G      1.418      1.603      1.598        320        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.412      0.433      0.322       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/70      21.2G      1.413      1.571      1.574        169        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.462      0.413      0.346      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/70      21.2G      1.379      1.533      1.542        234        960: 100% ━━━━━━━━━━━━ 59/59 1.0it/s 56.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618       0.45      0.426      0.375      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/70      20.5G      1.369      1.499      1.539        147        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.483      0.366      0.377      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/70      20.4G      1.383      1.527      1.562        260        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.397      0.462      0.336      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/70      21.3G      1.322      1.463      1.506        169        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618       0.49      0.499      0.401      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/70      20.2G       1.32      1.446      1.496        192        960: 100% ━━━━━━━━━━━━ 59/59 1.0it/s 1:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.511      0.416      0.423      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/70      20.5G      1.286      1.373      1.489        170        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.415       0.43      0.333      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/70      20.2G      1.297       1.38      1.479        245        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 50.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.424      0.458      0.342      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/70      20.4G      1.281      1.358      1.473        159        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.366      0.451       0.29      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/70      20.5G      1.259      1.339      1.454        190        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.533      0.443      0.447      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/70      21.2G       1.26      1.307      1.455        189        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 54.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.558      0.443      0.466      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/70      20.7G      1.246      1.309       1.45        394        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2it/s 1.6s\n",
            "                   all        320        618      0.589      0.424      0.457      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/70      20.5G      1.232      1.301      1.432        142        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.517      0.469      0.474       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/70      21.4G      1.205       1.28       1.42        172        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.509      0.502      0.477      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/70      20.2G      1.188      1.233      1.404        230        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.514      0.485      0.495      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/70      20.5G      1.202      1.232      1.404        202        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618       0.63      0.411       0.47      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/70      20.6G      1.173      1.207      1.401        247        960: 100% ━━━━━━━━━━━━ 59/59 1.0it/s 56.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2it/s 1.6s\n",
            "                   all        320        618      0.479      0.523      0.482      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/70      20.9G      1.178      1.216      1.393        185        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.529      0.471      0.453      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/70      20.3G      1.181      1.179      1.378        217        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.564      0.443       0.51      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/70      20.6G      1.169      1.183       1.37        137        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618       0.61      0.505      0.551      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/70      20.5G      1.176      1.164      1.378        377        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 55.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.565       0.51      0.542      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/70      20.5G      1.142      1.131      1.359        225        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.659      0.473      0.549      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/70      20.4G       1.13      1.122      1.345        157        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.616      0.504      0.539      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/70      20.4G      1.143      1.108      1.349        153        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 54.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.632      0.474      0.546      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/70      20.6G      1.108      1.082      1.342        240        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.4s\n",
            "                   all        320        618      0.497       0.57       0.54      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/70      20.6G       1.14      1.092      1.351        203        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.577       0.56      0.576      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/70      20.5G      1.108      1.104      1.326        153        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618       0.57      0.445       0.53      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/70      20.6G      1.124      1.064      1.335        121        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.6it/s 1.4s\n",
            "                   all        320        618       0.52      0.524       0.55      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/70      20.7G      1.086      1.018       1.31        210        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.486      0.604      0.508      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/70      20.4G      1.073      1.012      1.298        126        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.556      0.533      0.562      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/70      20.6G      1.064     0.9972      1.304        161        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.577      0.552      0.557      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/70      20.5G      1.068     0.9978      1.303        173        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.559      0.583      0.585      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/70      20.5G      1.038     0.9433      1.277        185        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 54.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.574      0.515      0.515      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/70      21.8G      1.051     0.9592      1.293        170        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.564       0.54      0.521      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/70      21.3G      1.039     0.9387      1.282        177        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.653      0.565      0.633      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/70      21.1G      1.044     0.9274      1.285        142        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 56.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.603      0.524      0.574      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/70      21.4G      1.025     0.9235      1.273        151        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 50.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.659      0.464      0.536      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/70      20.4G     0.9953     0.8986      1.259        191        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 54.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.622       0.53       0.56      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/70      20.6G     0.9828     0.8555      1.243        159        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.552      0.554      0.573      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/70      20.3G      1.026     0.8877      1.257        152        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.618      0.539      0.589       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/70      21.2G     0.9879     0.8489      1.229        179        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.656      0.578      0.616      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/70      20.7G     0.9815      0.846       1.23        197        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 54.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3it/s 1.5s\n",
            "                   all        320        618      0.605      0.615      0.618      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      51/70      20.4G     0.9781      0.845      1.223        168        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.635      0.551      0.609      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      52/70      20.5G     0.9438     0.8069      1.217        180        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 51.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.612      0.583      0.597      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      53/70      20.5G     0.9764     0.8156       1.23        163        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 51.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.623      0.526      0.573      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      54/70      20.5G     0.9598     0.7944      1.215        144        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.653       0.54      0.586      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      55/70      20.5G     0.9287     0.7671      1.201        188        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.605      0.565      0.573      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      56/70      20.7G     0.9431     0.7727      1.215        162        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 50.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.612      0.494      0.529       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      57/70      20.5G     0.9265     0.7582      1.193        171        960: 100% ━━━━━━━━━━━━ 59/59 1.0it/s 56.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.6it/s 1.4s\n",
            "                   all        320        618      0.633      0.526      0.564      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      58/70      20.6G      0.924     0.7416      1.196        151        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.613      0.543      0.563      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      59/70      20.6G     0.9098     0.7469      1.187        167        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 55.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.6it/s 1.4s\n",
            "                   all        320        618       0.61      0.537      0.573      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      60/70      20.5G     0.9228     0.7361      1.187        217        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618      0.617      0.505      0.551       0.39\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      61/70      21.2G     0.9222     0.7477      1.194        149        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.646      0.496       0.55      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      62/70      20.4G     0.9128     0.7028      1.194         67        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 48.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.624      0.518      0.555       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      63/70      20.5G     0.9012     0.6761      1.187        154        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 52.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.6it/s 1.4s\n",
            "                   all        320        618      0.574      0.552      0.559      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      64/70      20.5G     0.8896     0.6615      1.173         82        960: 100% ━━━━━━━━━━━━ 59/59 1.1it/s 51.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.607      0.536      0.569      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      65/70      20.4G     0.8878     0.6577      1.175         73        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 51.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.591      0.559      0.567      0.392\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      66/70      21.2G     0.8818      0.645       1.17         65        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 48.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618        0.6      0.551      0.567      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      67/70      21.3G     0.8805     0.6445      1.166         98        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 48.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618       0.59      0.558      0.573      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      68/70      20.5G     0.8662     0.6333      1.159         77        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 50.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.5it/s 1.4s\n",
            "                   all        320        618      0.602      0.544      0.568      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      69/70      21.1G     0.8736     0.6293      1.165        174        960: 100% ━━━━━━━━━━━━ 59/59 1.2it/s 49.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s\n",
            "                   all        320        618        0.6      0.555      0.568      0.402\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 49, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "69 epochs completed in 1.087 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink/weights/best.pt...\n",
            "Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.8it/s 2.8s\n",
            "                   all        320        618      0.659      0.574      0.615      0.428\n",
            "Speed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink\u001b[0m\n",
            "[SAVE_DIR] /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink\n",
            "[ARCHIVE] Eğitim klasörü arşivlendi -> /content/drive/MyDrive/censorly-training/alcohol/archives/yolo11s_true_false_detect_960_symlink_20250915_104358\n",
            "[SAVE] /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink/weights/best.pt  ->  /content/drive/MyDrive/censorly-training/alcohol/best_detect_960_symlink.pt\n",
            "[SAVE] /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink/weights/last.pt  ->  /content/drive/MyDrive/censorly-training/alcohol/last_detect_960_symlink.pt\n",
            "\n",
            "[VAL/TEST] Test split üzerinde değerlendirme başlıyor…\n",
            "Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.0±0.0 MB/s, size: 44.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/alcohol_mix/labels/test... 264 images, 65 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 264/264 5.5it/s 48.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/alcohol_mix/labels/test.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.3it/s 31.4s\n",
            "                   all        264        382      0.534      0.694      0.614      0.493\n",
            "Speed: 1.8ms preprocess, 2.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_TEST_EVAL\u001b[0m\n",
            "[VAL DONE] Çıktılar -> /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_TEST_EVAL\n",
            "\n",
            "[PREDICT] Test görsellerinden örnek tahminler kaydediliyor…\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_pred_examples\u001b[0m\n",
            "196 labels saved to /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_pred_examples/labels\n",
            "[PRED DONE] Örnekler -> /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_pred_examples\n",
            "\n",
            "[FINISHED] Eğitim + Test değerlendirme + Örnek pred. tamam.\n",
            "Eğitim klasörü: /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink\n",
            "Arşiv klasörü  : /content/drive/MyDrive/censorly-training/alcohol/archives/yolo11s_true_false_detect_960_symlink_20250915_104358\n",
            "Test eval klas.: /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_TEST_EVAL\n",
            "Pred örnek klas: /content/drive/MyDrive/censorly-training/alcohol/runs_detect/yolo11s_true_false_detect_960_symlink_pred_examples\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# YOLOv11/YOLOv8 DETECTION — Alcohol True vs False (oranı koru, 1:1 dayatma yok)\n",
        "# True:  /MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3/{images,labels}/{train,validation,test}\n",
        "# False: /MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/{images,labels}/{train,validation,test}\n",
        "# ==========================================\n",
        "%pip -q install --upgrade \"ultralytics>=8.3.0\" pillow opencv-python tqdm\n",
        "\n",
        "import os, shutil, time, random\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ---------- Kullanıcı ayarları ----------\n",
        "IMGSZ        = 960\n",
        "EPOCHS       = 70\n",
        "BATCH        = -1       # AutoBatch\n",
        "WORKERS      = 2        # Drive yavaşsa 0 yap\n",
        "SEED         = 42\n",
        "RUN_NAME     = f\"yolo11s_true_false_detect_{IMGSZ}_symlink\"\n",
        "STAGE_MODE   = \"symlink\"   # \"symlink\" önerilir; \"copy\" istersen değiştir\n",
        "\n",
        "# ---------- Drive & yollar ----------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.isdir('/content/drive/MyDrive'):\n",
        "        print(\"[MOUNT] Drive bağlanıyor...\")\n",
        "        drive.mount('/content/drive')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "DRIVE      = Path('/content/drive/MyDrive')\n",
        "DATA_ROOT  = DRIVE/'censorly-dataset'/'Alcohol'\n",
        "\n",
        "# ✅ True klasörü yeni dizine göre\n",
        "TRUE_DIR   = DATA_ROOT/'Alcohol-True'/'Edited-Alcohol-3'   # images/labels/{train,validation,test}\n",
        "# ✅ False aynı kalıyor\n",
        "FALSE_DIR  = DATA_ROOT/'Alcohol-False'/'Alcohol-False'     # images/labels/{train,validation,test}\n",
        "\n",
        "# Tüm run’ların, modellerin ve değerlendirme çıktılarının Drive’a yazılacağı ana klasör\n",
        "RUN_DIR       = DRIVE/'censorly-training'/'alcohol'\n",
        "PROJECT_DIR   = RUN_DIR/'runs_detect'  # Ultralytics 'project' paramı -> hepsi Drive’a\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PROJECT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Staging (eğitim okuma yolu; yerel/kolab diski)\n",
        "STAGE_ROOT = Path('/content/datasets/alcohol_mix')\n",
        "for s in ['train','validation','test']:\n",
        "    for sub in ['images','labels']:\n",
        "        (STAGE_ROOT/sub/s).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- Yardımcılar ----------\n",
        "IMG_EXTS = {'.jpg','.jpeg','.png','.bmp','.webp','.tif','.tiff','.jfif','.heic','.heif'}\n",
        "def is_img(p: Path): return p.is_file() and p.suffix.lower() in IMG_EXTS\n",
        "\n",
        "def layout_ok(base: Path):\n",
        "    # images/{train,validation,test} ve labels/{train,validation,test} var mı?\n",
        "    need = [(base/'images'/'train'), (base/'images'/'validation'), (base/'images'/'test'),\n",
        "            (base/'labels'/'train'), (base/'labels'/'validation'), (base/'labels'/'test')]\n",
        "    return all(p.exists() for p in need)\n",
        "\n",
        "def scan_split(base: Path, split: str, must_have_label: bool):\n",
        "    \"\"\"base: sınıf kökü (Edited-Alcohol-3 ya da Alcohol-False), split: train/validation/test\"\"\"\n",
        "    imgd = base/'images'/split\n",
        "    lbld = base/'labels'/split\n",
        "    items = []\n",
        "    if not imgd.exists():\n",
        "        return items\n",
        "    for img in imgd.rglob('*'):\n",
        "        if not is_img(img):\n",
        "            continue\n",
        "        lbl = lbld/(img.stem + '.txt')\n",
        "        if must_have_label:\n",
        "            if lbl.exists():\n",
        "                items.append((img, lbl))\n",
        "        else:\n",
        "            # Negatif için boş label yoksa oluştur\n",
        "            if not lbl.exists():\n",
        "                lbl.parent.mkdir(parents=True, exist_ok=True)\n",
        "                lbl.write_text('', encoding='utf-8')\n",
        "            items.append((img, lbl))\n",
        "    return items\n",
        "\n",
        "def safe_symlink(src: Path, dst: Path):\n",
        "    if dst.exists() or dst.is_symlink():\n",
        "        return\n",
        "    try:\n",
        "        os.symlink(src.as_posix(), dst.as_posix())\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "def stage_pair(src_img: Path, src_lbl: Path, dst_img: Path, dst_lbl: Path, mode=\"symlink\"):\n",
        "    if mode == \"symlink\":\n",
        "        safe_symlink(src_img, dst_img)\n",
        "        if src_lbl.exists(): safe_symlink(src_lbl, dst_lbl)\n",
        "        else: dst_lbl.write_text('', encoding='utf-8')\n",
        "    else:\n",
        "        if not dst_img.exists():\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "        if src_lbl.exists():\n",
        "            if not dst_lbl.exists():\n",
        "                shutil.copy2(src_lbl, dst_lbl)\n",
        "        else:\n",
        "            dst_lbl.write_text('', encoding='utf-8')\n",
        "\n",
        "# ---------- Kontroller ----------\n",
        "print(\"\\n[CHECK] TRUE:\", TRUE_DIR)\n",
        "if not TRUE_DIR.exists() or not layout_ok(TRUE_DIR):\n",
        "    raise FileNotFoundError(\n",
        "        f\"[ERR] True layout hatalı: {TRUE_DIR}\\n\"\n",
        "        \"Beklenen: .../Alcohol-True/Edited-Alcohol-3/{images,labels}/{train,validation,test}\"\n",
        "    )\n",
        "print(\"[OK] True layout doğru.\")\n",
        "\n",
        "print(\"[CHECK] FALSE:\", FALSE_DIR)\n",
        "if not FALSE_DIR.exists() or not layout_ok(FALSE_DIR):\n",
        "    raise FileNotFoundError(\n",
        "        f\"[ERR] False layout hatalı: {FALSE_DIR}\\n\"\n",
        "        \"Beklenen: .../Alcohol-False/Alcohol-False/{images,labels}/{train,validation,test}\"\n",
        "    )\n",
        "print(\"[OK] False layout doğru.\")\n",
        "\n",
        "# ---------- Sayımlar ve staging ----------\n",
        "random.seed(SEED)\n",
        "splits = ['train','validation','test']\n",
        "for split in splits:\n",
        "    pos = scan_split(TRUE_DIR,  split, must_have_label=True)\n",
        "    neg = scan_split(FALSE_DIR, split, must_have_label=False)  # boş txt'ler tamamlanır\n",
        "    print(f\"[COUNT {split:<10}] pos={len(pos):4d} | neg={len(neg):4d}\")\n",
        "\n",
        "    print(f\"\\n[STAGE {split}] Tüm pozitif + mevcut tüm negatif taşınıyor (mode={STAGE_MODE})\")\n",
        "    img_out = STAGE_ROOT/'images'/split\n",
        "    lbl_out = STAGE_ROOT/'labels'/split\n",
        "\n",
        "    # Pozitifleri taşı (etiketli)\n",
        "    cp_p = 0\n",
        "    for img, lbl in pos:\n",
        "        stem = f\"p__{img.stem}\"\n",
        "        dst_img = img_out/(stem + img.suffix.lower())\n",
        "        dst_lbl = lbl_out/(stem + '.txt')\n",
        "        stage_pair(img, lbl, dst_img, dst_lbl, STAGE_MODE)\n",
        "        cp_p += 1\n",
        "\n",
        "    # Negatifleri taşı (boş etiket)\n",
        "    cp_n = 0\n",
        "    for img, lbl in neg:\n",
        "        stem = f\"n__{img.stem}\"\n",
        "        dst_img = img_out/(stem + img.suffix.lower())\n",
        "        dst_lbl = lbl_out/(stem + '.txt')\n",
        "        stage_pair(img, lbl, dst_img, dst_lbl, STAGE_MODE)\n",
        "        cp_n += 1\n",
        "\n",
        "    print(f\"[DONE {split}] +pos={cp_p}  +neg={cp_n}\")\n",
        "\n",
        "# ---------- data.yaml ----------\n",
        "DATA_YAML = RUN_DIR/'data_true_false_detect.yaml'\n",
        "DATA_YAML.write_text(\n",
        "    \"\\n\".join([\n",
        "        \"train:\",\n",
        "        f\"  - {str((STAGE_ROOT/'images'/'train').resolve())}\",\n",
        "        \"val:\",\n",
        "        f\"  - {str((STAGE_ROOT/'images'/'validation').resolve())}\",\n",
        "        \"test:\",\n",
        "        f\"  - {str((STAGE_ROOT/'images'/'test').resolve())}\",\n",
        "        \"names:\",\n",
        "        \"  0: alcohol\",\n",
        "    ]) + \"\\n\",\n",
        "    encoding='utf-8'\n",
        ")\n",
        "print(\"\\n[YAML]\", DATA_YAML)\n",
        "\n",
        "# ---------- Ağırlık seçimi ----------\n",
        "candidate_weights = ['yolo11s.pt', 'yolov8s.pt']\n",
        "WEIGHTS_IN = None\n",
        "for w in candidate_weights:\n",
        "    try:\n",
        "        _ = YOLO(w)  # erişilebilir mi?\n",
        "        WEIGHTS_IN = w\n",
        "        break\n",
        "    except Exception:\n",
        "        WEIGHTS_IN = None\n",
        "if WEIGHTS_IN is None:\n",
        "    WEIGHTS_IN = 'yolov8s.pt'\n",
        "print(\"[MODEL] start_weights =\", WEIGHTS_IN)\n",
        "\n",
        "# ---------- Eğitim ----------\n",
        "print(\"\\n[TRAIN] başlıyor… (task=detect, single_cls=True)\")\n",
        "model = YOLO(WEIGHTS_IN)\n",
        "results = model.train(\n",
        "    data=str(DATA_YAML),\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMGSZ,\n",
        "    batch=BATCH,\n",
        "    workers=WORKERS,\n",
        "    project=str(PROJECT_DIR),\n",
        "    name=RUN_NAME,\n",
        "    exist_ok=True,\n",
        "    device=0,\n",
        "    patience=20,\n",
        "    cos_lr=True,\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.0015,\n",
        "    seed=SEED,\n",
        "    deterministic=True,\n",
        "    single_cls=True,   # tek sınıf (alcohol)\n",
        "    close_mosaic=10,\n",
        "    cache=False        # Drive yavaşsa STAGE_MODE='copy' + cache=True yapabilirsin\n",
        ")\n",
        "\n",
        "# ---------- Eğitim klasörünü Drive’da sakla (tümüyle) ----------\n",
        "save_dir  = Path(getattr(getattr(model,'trainer',None),'save_dir', PROJECT_DIR/ RUN_NAME))\n",
        "print(\"[SAVE_DIR]\", save_dir)\n",
        "\n",
        "# timestamp’lı bir kopya (istersen direkt save_dir Drive’da zaten; yine de arşivlemek iyi olur)\n",
        "stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "archive_dir = RUN_DIR/'archives'/f\"{RUN_NAME}_{stamp}\"\n",
        "archive_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "if archive_dir.exists():\n",
        "    shutil.rmtree(archive_dir)\n",
        "shutil.copytree(save_dir, archive_dir)\n",
        "print(f\"[ARCHIVE] Eğitim klasörü arşivlendi -> {archive_dir}\")\n",
        "\n",
        "# Ek olarak best/last ağırlıklarını da düz kopya olarak atalım\n",
        "weights   = save_dir/'weights'\n",
        "best_src  = weights/'best.pt'\n",
        "last_src  = weights/'last.pt'\n",
        "best_dst  = RUN_DIR/f'best_detect_{IMGSZ}_symlink.pt'\n",
        "last_dst  = RUN_DIR/f'last_detect_{IMGSZ}_symlink.pt'\n",
        "if best_src.exists():\n",
        "    shutil.copy2(best_src, best_dst); print(f\"[SAVE] {best_src}  ->  {best_dst}\")\n",
        "if last_src.exists():\n",
        "    shutil.copy2(last_src, last_dst); print(f\"[SAVE] {last_src}  ->  {last_dst}\")\n",
        "\n",
        "# ---------- TEST split değerlendirmesi (val() ile) ----------\n",
        "print(\"\\n[VAL/TEST] Test split üzerinde değerlendirme başlıyor…\")\n",
        "val_out_name = f\"{RUN_NAME}_TEST_EVAL\"\n",
        "val_results = model.val(\n",
        "    data=str(DATA_YAML),\n",
        "    imgsz=IMGSZ,\n",
        "    split='test',           # test split\n",
        "    save=True,              # PR/ROC/CM vs. plotları kaydet\n",
        "    plots=True,\n",
        "    project=str(PROJECT_DIR),\n",
        "    name=val_out_name,\n",
        "    conf=0.25,\n",
        "    iou=0.7\n",
        ")\n",
        "print(\"[VAL DONE] Çıktılar ->\", PROJECT_DIR/val_out_name)\n",
        "\n",
        "# ---------- Test görsellerinden örnek tahminler ----------\n",
        "print(\"\\n[PREDICT] Test görsellerinden örnek tahminler kaydediliyor…\")\n",
        "TEST_IMG_DIR = (STAGE_ROOT/'images'/'test')\n",
        "pred_name = f\"{RUN_NAME}_pred_examples\"\n",
        "pred_results = model.predict(\n",
        "    source=str(TEST_IMG_DIR),\n",
        "    imgsz=IMGSZ,\n",
        "    conf=0.25,\n",
        "    iou=0.7,\n",
        "    save=True,              # çizilmiş görselleri kaydet\n",
        "    save_txt=True,          # txt çıkışı\n",
        "    save_conf=True,         # txt’de confidence yaz\n",
        "    project=str(PROJECT_DIR),\n",
        "    name=pred_name,\n",
        "    max_det=50,\n",
        "    verbose=False\n",
        ")\n",
        "print(\"[PRED DONE] Örnekler ->\", PROJECT_DIR/pred_name)\n",
        "\n",
        "print(\"\\n[FINISHED] Eğitim + Test değerlendirme + Örnek pred. tamam.\")\n",
        "print(\"Eğitim klasörü:\", save_dir)\n",
        "print(\"Arşiv klasörü  :\", archive_dir)\n",
        "print(\"Test eval klas.:\", PROJECT_DIR/val_out_name)\n",
        "print(\"Pred örnek klas:\", PROJECT_DIR/pred_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O5bGokgeqNN",
        "outputId": "a4f203a2-61e8-44f8-9472-a191937803a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SUMMARY ===\n",
            "model: /content/drive/MyDrive/censorly-training/alcohol/finetune_with_all_neg2/weights/best.pt\n",
            "img_dir: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3/images/test\n",
            "lbl_dir: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3/labels/test\n",
            "images_evaluated: 199\n",
            "iou_thr: 0.5\n",
            "contain_thr: 0.8\n",
            "min_pred_conf_eval: 0.1\n",
            "iou_TP: 271\n",
            "iou_FP: 234\n",
            "iou_FN: 111\n",
            "iou_precision: 0.5366\n",
            "iou_recall: 0.7094\n",
            "iou_f1: 0.611\n",
            "contain_TP: 413\n",
            "contain_FP: 92\n",
            "contain_FN: 123\n",
            "contain_precision: 0.8178\n",
            "contain_recall: 0.7705\n",
            "contain_f1: 0.7935\n",
            "per_image_csv: /content/drive/MyDrive/censorly-training/alcohol/contain_eval_20250917_121401/per_image_metrics.csv\n",
            "boxes_detail_csv: /content/drive/MyDrive/censorly-training/alcohol/contain_eval_20250917_121401/boxes_detail.csv\n",
            "viz_dir: /content/drive/MyDrive/censorly-training/alcohol/contain_eval_20250917_121401/viz\n",
            "\n",
            "Outputs saved to: /content/drive/MyDrive/censorly-training/alcohol/contain_eval_20250917_121401\n"
          ]
        }
      ],
      "source": [
        "import os, glob, csv, json, math\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ====================== KULLANICI AYARLARI ======================\n",
        "MODEL_WEIGHTS = \"/content/drive/MyDrive/censorly-training/alcohol/finetune_with_all_neg2/weights/best.pt\"\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3/images/test\"\n",
        "LBL_DIR = \"/content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-True/Edited-Alcohol-3/labels/test\"\n",
        "\n",
        "SAVE_VIS = True  # kutulu görselleri kaydet\n",
        "CONF_INFER = 0.30  # inference için düşük eşik\n",
        "IMGSZ = 960\n",
        "\n",
        "# Değerlendirme eşikleri\n",
        "IOU_THR = 0.50              # standart IoU metriği için\n",
        "CONTAIN_THR = 0.80          # pred'in en az bu oranla GT içinde olması (inter/pred_area)\n",
        "MIN_PRED_CONF_FOR_EVAL = 0.10  # değerlendirmeye dahil edilmesi için min skor\n",
        "\n",
        "# Çıktı klasörü\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUT_DIR = Path(f\"/content/drive/MyDrive/censorly-training/alcohol/contain_eval_{ts}\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VIS_DIR = OUT_DIR / \"viz\"\n",
        "if SAVE_VIS:\n",
        "    VIS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ===============================================================\n",
        "\n",
        "\n",
        "def yolo_label_to_xyxy(lbl, w, h):\n",
        "    # YOLO txt: cls cx cy bw bh (hepsi [0,1])\n",
        "    c, cx, cy, bw, bh = lbl\n",
        "    x1 = (cx - bw / 2.0) * w\n",
        "    y1 = (cy - bh / 2.0) * h\n",
        "    x2 = (cx + bw / 2.0) * w\n",
        "    y2 = (cy + bh / 2.0) * h\n",
        "    return int(c), np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    x1 = max(a[0], b[0]); y1 = max(a[1], b[1])\n",
        "    x2 = min(a[2], b[2]); y2 = min(a[3], b[3])\n",
        "    iw = max(0.0, x2 - x1); ih = max(0.0, y2 - y1)\n",
        "    inter = iw * ih\n",
        "    area_a = max(0.0, (a[2]-a[0]) * (a[3]-a[1]))\n",
        "    area_b = max(0.0, (b[2]-b[0]) * (b[3]-b[1]))\n",
        "    union = area_a + area_b - inter + 1e-9\n",
        "    return inter / union\n",
        "\n",
        "def inter_over_pred_area(pred, gt):\n",
        "    x1 = max(pred[0], gt[0]); y1 = max(pred[1], gt[1])\n",
        "    x2 = min(pred[2], gt[2]); y2 = min(pred[3], gt[3])\n",
        "    iw = max(0.0, x2 - x1); ih = max(0.0, y2 - y1)\n",
        "    inter = iw * ih\n",
        "    p_area = max(1e-9, (pred[2]-pred[0]) * (pred[3]-pred[1]))\n",
        "    return inter / p_area\n",
        "\n",
        "def greedy_iou_match(gts, preds, thr=0.5):\n",
        "    \"\"\"\n",
        "    gts: [G,4], preds: [P,4] (skorları -> sıralama için ayrıca ver)\n",
        "    1-e-1 TP sayımı için greedy IoU eşleştirme.\n",
        "    \"\"\"\n",
        "    G = len(gts); P = len(preds)\n",
        "    used_g = set(); used_p = set()\n",
        "    tps = 0\n",
        "    for pi in range(P):\n",
        "        best_iou, best_g = -1.0, -1\n",
        "        for gi in range(G):\n",
        "            if gi in used_g:\n",
        "                continue\n",
        "            iou = iou_xyxy(preds[pi], gts[gi])\n",
        "            if iou >= thr and iou > best_iou:\n",
        "                best_iou, best_g = iou, gi\n",
        "        if best_g >= 0:\n",
        "            used_g.add(best_g); used_p.add(pi); tps += 1\n",
        "    fps = P - tps\n",
        "    fns = G - len(used_g)\n",
        "    return tps, fps, fns\n",
        "\n",
        "def containment_count(gts, preds, thr=0.8):\n",
        "    \"\"\"\n",
        "    Bir GT içine giren tüm pred'ler TP.\n",
        "    TP: inter/pred_area >= thr sağlayan tüm pred'ler.\n",
        "    FP: diğer tüm pred'ler.\n",
        "    FN: hiçbir pred tarafından 'yeterince kapsanmayan' GT'ler.\n",
        "    \"\"\"\n",
        "    P = len(preds); G = len(gts)\n",
        "    if P == 0 and G == 0:\n",
        "        return 0, 0, 0\n",
        "    if P == 0:\n",
        "        return 0, 0, G\n",
        "    if G == 0:\n",
        "        return 0, P, 0\n",
        "\n",
        "    tp_flags = np.zeros(P, dtype=bool)\n",
        "    gt_hit = np.zeros(G, dtype=bool)\n",
        "\n",
        "    for pi in range(P):\n",
        "        for gi in range(G):\n",
        "            r = inter_over_pred_area(preds[pi], gts[gi])\n",
        "            if r >= thr:\n",
        "                tp_flags[pi] = True\n",
        "                gt_hit[gi] = True  # en az bir pred bu GT'yi kapsadı\n",
        "    TP = int(tp_flags.sum())\n",
        "    FP = int(P - TP)\n",
        "    FN = int(G - gt_hit.sum())\n",
        "    return TP, FP, FN\n",
        "\n",
        "def draw(img, gts, preds, title=\"\"):\n",
        "    out = img.copy()\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    # GT: YEŞİL\n",
        "    for b in gts:\n",
        "        x1,y1,x2,y2 = b.astype(int)\n",
        "        cv2.rectangle(out, (x1,y1), (x2,y2), (60,180,60), 2)\n",
        "    # Pred: MAVİ\n",
        "    for b in preds:\n",
        "        x1,y1,x2,y2 = b.astype(int)\n",
        "        cv2.rectangle(out, (x1,y1), (x2,y2), (255,120,0), 2)\n",
        "    if title:\n",
        "        cv2.putText(out, title, (10,25), font, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
        "        cv2.putText(out, title, (10,25), font, 0.7, (255,255,255), 1, cv2.LINE_AA)\n",
        "    return out\n",
        "\n",
        "# --- Model ---\n",
        "assert Path(MODEL_WEIGHTS).exists(), f\"Model yok: {MODEL_WEIGHTS}\"\n",
        "model = YOLO(MODEL_WEIGHTS)\n",
        "\n",
        "# --- Görseller ---\n",
        "img_exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\")\n",
        "img_paths = []\n",
        "for ext in img_exts:\n",
        "    img_paths += glob.glob(str(Path(IMG_DIR)/ext))\n",
        "img_paths = sorted(img_paths)\n",
        "assert len(img_paths) > 0, f\"Görsel bulunamadı: {IMG_DIR}\"\n",
        "\n",
        "# --- CSV hazırlık ---\n",
        "per_img_csv = OUT_DIR / \"per_image_metrics.csv\"\n",
        "detail_csv = OUT_DIR / \"boxes_detail.csv\"\n",
        "\n",
        "with open(per_img_csv, \"w\", newline=\"\") as f1, open(detail_csv, \"w\", newline=\"\") as f2:\n",
        "    w1 = csv.writer(f1)\n",
        "    w2 = csv.writer(f2)\n",
        "    w1.writerow([\n",
        "        \"image\",\"gt_count\",\"pred_count\",\n",
        "        \"TP_iou\",\"FP_iou\",\"FN_iou\",\n",
        "        \"TP_cont\",\"FP_cont\",\"FN_cont\"\n",
        "    ])\n",
        "    w2.writerow([\n",
        "        \"image\",\"kind\",\"x1\",\"y1\",\"x2\",\"y2\",\"conf\"\n",
        "    ])\n",
        "\n",
        "    # --- Toplamlar ---\n",
        "    TP_iou=FP_iou=FN_iou=0\n",
        "    TP_cont=FP_cont=FN_cont=0\n",
        "\n",
        "    for res in model.predict(source=img_paths, conf=CONF_INFER, imgsz=IMGSZ, save=False, stream=True, verbose=False):\n",
        "        im_path = Path(res.path)\n",
        "        img = cv2.imread(str(im_path)); H,W = img.shape[:2]\n",
        "\n",
        "        # GT oku\n",
        "        gt_file = Path(LBL_DIR) / (im_path.stem + \".txt\")\n",
        "        gts = []\n",
        "        if gt_file.exists():\n",
        "            with open(gt_file, \"r\") as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) != 5:\n",
        "                        continue\n",
        "                    c,cx,cy,bw,bh = map(float, parts)\n",
        "                    _, box = yolo_label_to_xyxy([c,cx,cy,bw,bh], W, H)\n",
        "                    gts.append(box)\n",
        "        gts = np.array(gts, dtype=np.float32)\n",
        "\n",
        "        # Pred'ler\n",
        "        preds = []\n",
        "        if res.boxes is not None and len(res.boxes) > 0:\n",
        "            xyxy = res.boxes.xyxy.detach().cpu().numpy()\n",
        "            conf = res.boxes.conf.detach().cpu().numpy()\n",
        "            # değerlendirmeye alınacak skorlar\n",
        "            mask = conf >= MIN_PRED_CONF_FOR_EVAL\n",
        "            xyxy = xyxy[mask]; conf = conf[mask]\n",
        "            preds = xyxy\n",
        "\n",
        "            # detay CSV: pred\n",
        "            for i in range(len(xyxy)):\n",
        "                x1,y1,x2,y2 = xyxy[i].tolist()\n",
        "                w2.writerow([str(im_path),\"pred\",x1,y1,x2,y2,float(conf[i])])\n",
        "        else:\n",
        "            preds = np.zeros((0,4), dtype=np.float32)\n",
        "\n",
        "        # detay CSV: gt\n",
        "        for box in gts:\n",
        "            x1,y1,x2,y2 = box.tolist()\n",
        "            w2.writerow([str(im_path),\"gt\",x1,y1,x2,y2,\"\"])\n",
        "\n",
        "        # --- METRİKLER ---\n",
        "        # IoU: skor sıralı greedy 1-e-1 (skora göre sırala)\n",
        "        if preds.shape[0] > 0 and res.boxes is not None:\n",
        "            conf_all = res.boxes.conf.detach().cpu().numpy()\n",
        "            if len(conf_all) == preds.shape[0]:\n",
        "                order = np.argsort(-conf_all)\n",
        "                preds_iou = preds[order]\n",
        "            else:\n",
        "                preds_iou = preds\n",
        "        else:\n",
        "            preds_iou = preds\n",
        "\n",
        "        ti,fi,ni = greedy_iou_match(gts, preds_iou, thr=IOU_THR)\n",
        "        tc,fc,nc = containment_count(gts, preds, thr=CONTAIN_THR)\n",
        "\n",
        "        TP_iou += ti; FP_iou += fi; FN_iou += ni\n",
        "        TP_cont += tc; FP_cont += fc; FN_cont += nc\n",
        "\n",
        "        # per-image yaz\n",
        "        w1.writerow([str(im_path), len(gts), len(preds), ti, fi, ni, tc, fc, nc])\n",
        "\n",
        "        # görsel kaydet\n",
        "        if SAVE_VIS:\n",
        "            title = f\"IOU(TP:{ti}/FP:{fi}/FN:{ni})  |  CONT(TP:{tc}/FP:{fc}/FN:{nc})\"\n",
        "            vis = draw(img, gts, preds, title=title)\n",
        "            cv2.imwrite(str(VIS_DIR / f\"{im_path.stem}.jpg\"), vis)\n",
        "\n",
        "# --- Özet rapor ---\n",
        "def prf(tp, fp, fn):\n",
        "    prec = tp / (tp+fp) if (tp+fp)>0 else 0.0\n",
        "    rec  = tp / (tp+fn) if (tp+fn)>0 else 0.0\n",
        "    f1   = (2*prec*rec/(prec+rec)) if (prec+rec)>0 else 0.0\n",
        "    return round(prec,4), round(rec,4), round(f1,4)\n",
        "\n",
        "prec_i, rec_i, f1_i = prf(TP_iou, FP_iou, FN_iou)\n",
        "prec_c, rec_c, f1_c = prf(TP_cont, FP_cont, FN_cont)\n",
        "\n",
        "summary = {\n",
        "    \"model\": MODEL_WEIGHTS,\n",
        "    \"img_dir\": IMG_DIR,\n",
        "    \"lbl_dir\": LBL_DIR,\n",
        "    \"images_evaluated\": len(img_paths),\n",
        "    \"iou_thr\": IOU_THR,\n",
        "    \"contain_thr\": CONTAIN_THR,\n",
        "    \"min_pred_conf_eval\": MIN_PRED_CONF_FOR_EVAL,\n",
        "    \"iou_TP\": TP_iou, \"iou_FP\": FP_iou, \"iou_FN\": FN_iou,\n",
        "    \"iou_precision\": prec_i, \"iou_recall\": rec_i, \"iou_f1\": f1_i,\n",
        "    \"contain_TP\": TP_cont, \"contain_FP\": FP_cont, \"contain_FN\": FN_cont,\n",
        "    \"contain_precision\": prec_c, \"contain_recall\": rec_c, \"contain_f1\": f1_c,\n",
        "    \"per_image_csv\": str(per_img_csv),\n",
        "    \"boxes_detail_csv\": str(detail_csv),\n",
        "    \"viz_dir\": str(VIS_DIR) if SAVE_VIS else None,\n",
        "}\n",
        "\n",
        "with open(OUT_DIR/\"summary.json\", \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "for k,v in summary.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "print(f\"\\nOutputs saved to: {OUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exbpy7SBThQO",
        "outputId": "ad66ddb3-c9ca-4e58-acff-5fef2d7ff90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Kopyalanan orijinal img: 15\n",
            "[INFO] Kopyalanan pred görseli: 15\n",
            "\n",
            "=== FP Dağılımı (score_bin x dets_bin) ===\n",
            "score_bin  dets_bin\n",
            "0.60–0.75  1           2\n",
            "0.75–0.90  1           7\n",
            "           2–3         3\n",
            "<0.60      1           3\n",
            "dtype: int64\n",
            "\n",
            "=== Negatif sette yaklaşık FP oranı (max_conf eşiğine göre) ===\n",
            "{'conf': 0.5, 'approx_fp_rate': np.float64(0.375)}\n",
            "{'conf': 0.55, 'approx_fp_rate': np.float64(0.35)}\n",
            "{'conf': 0.6, 'approx_fp_rate': np.float64(0.3)}\n",
            "{'conf': 0.65, 'approx_fp_rate': np.float64(0.275)}\n",
            "{'conf': 0.7, 'approx_fp_rate': np.float64(0.25)}\n",
            "{'conf': 0.75, 'approx_fp_rate': np.float64(0.25)}\n",
            "{'conf': 0.8, 'approx_fp_rate': np.float64(0.175)}\n",
            "{'conf': 0.85, 'approx_fp_rate': np.float64(0.15)}\n",
            "{'conf': 0.9, 'approx_fp_rate': np.float64(0.0)}\n"
          ]
        }
      ],
      "source": [
        "# === FP İnceleme — summary.csv Şemasına Göre Düzenlendi ===\n",
        "import pandas as pd, os, shutil, math, cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ----- Yollar -----\n",
        "RUN_DIR = Path(\"/content/false_sample_test_20250917_114351\")  # senin çıktı dizinin\n",
        "CSV = RUN_DIR/\"summary.csv\"          # summary.csv (bu dizinde olmalı)\n",
        "FP_DIR = RUN_DIR/\"fp_review\"         # inceleme klasörü\n",
        "FP_IMG_DIR = FP_DIR/\"images\"         # orijinal img kopyaları\n",
        "FP_PRED_DIR = FP_DIR/\"preds\"         # işaretli pred kopyaları\n",
        "for d in [FP_DIR, FP_IMG_DIR, FP_PRED_DIR]:\n",
        "    d.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# ----- CSV'yi oku (senin şema) -----\n",
        "# Beklenen kolonlar: image, saved_pred, num_dets, max_conf, classes, is_false_positive\n",
        "df = pd.read_csv(CSV)\n",
        "\n",
        "# Tip güvenliği (bazı CSV'lerde bool/int karışabilir)\n",
        "df[\"is_false_positive\"] = df[\"is_false_positive\"].astype(int)\n",
        "df[\"num_dets\"] = df[\"num_dets\"].astype(int)\n",
        "df[\"max_conf\"] = df[\"max_conf\"].astype(float)\n",
        "\n",
        "# ----- FP satırları -----\n",
        "fp = df[df[\"is_false_positive\"] == 1].copy()\n",
        "\n",
        "# Görselleri kopyala (varsa)\n",
        "def safe_copy(src_path: Path, dst_path: Path):\n",
        "    try:\n",
        "        if src_path.exists():\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Kopyalanamadı: {src_path} -> {dst_path.name} ({e})\")\n",
        "    return False\n",
        "\n",
        "copied_img = 0\n",
        "copied_pred = 0\n",
        "for _, row in fp.iterrows():\n",
        "    # Orijinal görsel\n",
        "    img_p = Path(str(row[\"image\"]).strip())\n",
        "    if img_p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"]:\n",
        "        if safe_copy(img_p, FP_IMG_DIR/img_p.name):\n",
        "            copied_img += 1\n",
        "    # Prediction görseli (işaretli)\n",
        "    pred_p = Path(str(row[\"saved_pred\"]).strip()) if \"saved_pred\" in row and not pd.isna(row[\"saved_pred\"]) else None\n",
        "    if pred_p and pred_p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"]:\n",
        "        if safe_copy(pred_p, FP_PRED_DIR/pred_p.name):\n",
        "            copied_pred += 1\n",
        "\n",
        "print(f\"[INFO] Kopyalanan orijinal img: {copied_img}\")\n",
        "print(f\"[INFO] Kopyalanan pred görseli: {copied_pred}\")\n",
        "\n",
        "# ----- Hızlı özet: skor & tespit sayısı kümeleri -----\n",
        "def bin_score(x):\n",
        "    if x < 0.60: return \"<0.60\"\n",
        "    if x < 0.75: return \"0.60–0.75\"\n",
        "    if x < 0.90: return \"0.75–0.90\"\n",
        "    return \"≥0.90\"\n",
        "\n",
        "def bin_dets(n):\n",
        "    if n == 0: return \"0\"\n",
        "    if n == 1: return \"1\"\n",
        "    if n <= 3: return \"2–3\"\n",
        "    if n <= 6: return \"4–6\"\n",
        "    return \"7+\"\n",
        "\n",
        "fp[\"score_bin\"] = fp[\"max_conf\"].apply(bin_score)\n",
        "fp[\"dets_bin\"]  = fp[\"num_dets\"].apply(bin_dets)\n",
        "\n",
        "print(\"\\n=== FP Dağılımı (score_bin x dets_bin) ===\")\n",
        "print(fp.groupby([\"score_bin\",\"dets_bin\"]).size().sort_index())\n",
        "\n",
        "# ----- Contact sheet (6'lı), varsa işaretli pred görsellerinden; yoksa orijinallerden -----\n",
        "def make_contact_sheets(src_dir: Path, out_prefix: str, rows=2, cols=3, thumb=360):\n",
        "    imgs = sorted([p for p in src_dir.glob(\"*\") if p.suffix.lower() in [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]])\n",
        "    if not imgs:\n",
        "        print(f\"[INFO] Contact için görsel yok: {src_dir}\")\n",
        "        return\n",
        "\n",
        "    pages = math.ceil(len(imgs)/(rows*cols))\n",
        "    for pg in range(pages):\n",
        "        # beyaz tuval\n",
        "        canvas = np.full((thumb*rows, thumb*cols, 3), 255, dtype=np.uint8)\n",
        "        for i in range(rows*cols):\n",
        "            idx = pg*(rows*cols)+i\n",
        "            if idx>=len(imgs): break\n",
        "            im = cv2.imread(str(imgs[idx]))\n",
        "            if im is None: continue\n",
        "            im = cv2.resize(im, (thumb,thumb))\n",
        "            r, c = divmod(i, cols)\n",
        "            canvas[r*thumb:(r+1)*thumb, c*thumb:(c+1)*thumb] = im\n",
        "        out = str(RUN_DIR/f\"{out_prefix}_{pg+1}.jpg\")\n",
        "        cv2.imwrite(out, canvas)\n",
        "        print(\"saved\", out)\n",
        "# ----- (Opsiyonel) Conf eşiği süpürme — negatif sette yaklaşık FP oranı -----\n",
        "# Not: summary.csv per-image 'max_conf' içerdiğinden, ~yaklaşık olarak\n",
        "# conf>=t olan görüntüleri FP sayıyoruz (detay bbox bazlı değil ama pratikte iş görüyor).\n",
        "import numpy as np\n",
        "confs = np.linspace(0.50, 0.90, 9)\n",
        "rows = []\n",
        "neg_total = len(df)  # tamamı negatif set olduğundan 40\n",
        "for c in confs:\n",
        "    fp_at_c = (df[\"max_conf\"] >= c).sum()\n",
        "    rows.append({\"conf\": round(float(c),2), \"approx_fp_rate\": round(fp_at_c/neg_total, 4)})\n",
        "\n",
        "print(\"\\n=== Negatif sette yaklaşık FP oranı (max_conf eşiğine göre) ===\")\n",
        "for r in rows:\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUZ5YPUObkKV",
        "outputId": "50f37784-852f-4b78-eb99-e86a1cb5a644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.201 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/drive/MyDrive/censorly-training/alcohol/data_with_all_neg.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=12, erasing=0.0, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01, hsv_s=0.4, hsv_v=0.25, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.002, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/censorly-training/alcohol/finetune_with_all_neg/weights/best.pt, momentum=0.937, mosaic=0.3, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0003, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding class names with single class.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "YOLO11s summary: 181 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 50.1±16.9 MB/s, size: 110.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/train.cache... 2139 images, 358 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2139/2139 3.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA A100-SXM4-40GB) 39.56G total, 27.21G reserved, 0.13G allocated, 12.22G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     9428179       21.55         0.837         34.59         29.22        (1, 3, 640, 640)                    list\n",
            "     9428179        43.1         1.187         33.18         30.87        (2, 3, 640, 640)                    list\n",
            "     9428179       86.19         1.795         35.01         31.72        (4, 3, 640, 640)                    list\n",
            "     9428179       172.4         2.896         40.13          32.9        (8, 3, 640, 640)                    list\n",
            "     9428179       344.8         5.121          40.1         41.46       (16, 3, 640, 640)                    list\n",
            "     9428179       689.6         9.485         43.22         67.45       (32, 3, 640, 640)                    list\n",
            "     9428179        1379        17.989         80.46         121.6       (64, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 23 for CUDA:0 34.28G/39.56G (87%) ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 40.1±24.8 MB/s, size: 100.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/train.cache... 2139 images, 358 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2139/2139 3.3Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.6±0.8 ms, read: 33.3±15.6 MB/s, size: 708.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/validation.cache... 320 images, 123 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 320/320 366.0Kit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005390625), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/12      5.99G      1.011     0.8142       1.15         92        640: 100% ━━━━━━━━━━━━ 93/93 3.0it/s 30.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.4it/s 17.2s\n",
            "                   all        320        618      0.589      0.516      0.559       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/12      7.25G      1.021      0.814      1.146        127        640: 100% ━━━━━━━━━━━━ 93/93 6.6it/s 14.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 6.1it/s 1.1s\n",
            "                   all        320        618      0.616      0.529      0.567      0.381\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/12      7.27G      1.032     0.8503      1.168         72        640: 100% ━━━━━━━━━━━━ 93/93 5.7it/s 16.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.7it/s 1.2s\n",
            "                   all        320        618      0.638      0.465      0.537      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/12       7.3G      1.046     0.8792      1.186         45        640: 100% ━━━━━━━━━━━━ 93/93 6.7it/s 13.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.5it/s 1.3s\n",
            "                   all        320        618       0.63      0.427      0.517      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/12       7.3G       1.04      0.879      1.176         47        640: 100% ━━━━━━━━━━━━ 93/93 6.8it/s 13.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 6.0it/s 1.2s\n",
            "                   all        320        618      0.626      0.484      0.559       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/12       7.3G     0.9967     0.8085      1.141         57        640: 100% ━━━━━━━━━━━━ 93/93 6.8it/s 13.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.6it/s 1.3s\n",
            "                   all        320        618      0.638       0.44      0.523      0.367\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "6 epochs completed in 0.036 hours.\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating /content/runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.201 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.4it/s 2.1s\n",
            "                   all        320        618      0.589      0.517      0.559       0.39\n",
            "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train2\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7df3fd9071a0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97959,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,\n",
              "            0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,\n",
              "            0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.97521,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96947,     0.96575,\n",
              "            0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96575,     0.96078,     0.96078,\n",
              "            0.96078,     0.96078,     0.96078,     0.96078,     0.96078,     0.96078,     0.96078,     0.96078,     0.95484,     0.95484,     0.95062,     0.95062,     0.95062,     0.95062,     0.95062,     0.95062,     0.95062,     0.95062,     0.95062,      0.9422,      0.9422,      0.9422,      0.9422,\n",
              "             0.9422,      0.9422,      0.9422,      0.9422,      0.9422,      0.9422,      0.9422,      0.9422,      0.9422,      0.9422,      0.9422,     0.93714,     0.93714,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,     0.93478,\n",
              "            0.93478,     0.93478,     0.93478,     0.92513,     0.92147,     0.92147,     0.92147,     0.92147,     0.92147,     0.91327,     0.91327,     0.91327,     0.91327,     0.91327,     0.90909,       0.905,       0.905,     0.89756,     0.89756,     0.89756,     0.89756,     0.89756,     0.89151,\n",
              "            0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.88372,     0.88372,     0.88182,     0.88182,     0.88182,     0.88182,     0.88182,     0.88182,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,\n",
              "            0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.87983,     0.86831,     0.86831,     0.86831,     0.86831,     0.86831,     0.86831,     0.86831,     0.86831,     0.86831,     0.86831,       0.868,       0.868,       0.868,\n",
              "              0.868,       0.868,       0.868,       0.868,       0.868,       0.868,     0.86561,     0.86561,     0.86561,     0.86561,     0.86275,     0.86047,     0.86047,     0.86047,     0.85878,     0.85878,     0.85878,     0.85878,     0.85878,     0.84962,     0.84962,     0.84758,     0.84758,\n",
              "            0.84758,     0.83577,     0.83577,     0.83453,     0.83453,     0.83453,     0.83453,     0.83453,     0.82979,     0.82979,     0.82979,     0.82807,     0.82807,     0.82807,     0.82578,     0.82578,     0.82353,     0.80537,     0.80537,     0.80537,     0.79868,     0.79868,     0.79868,\n",
              "            0.79868,     0.77885,      0.7746,      0.7746,     0.76923,     0.76923,     0.76923,     0.76923,     0.76923,     0.76923,     0.76923,     0.76923,     0.76923,     0.76923,     0.76596,     0.76596,     0.76596,     0.76506,     0.76506,     0.76506,     0.76119,     0.76119,     0.76036,\n",
              "            0.76036,     0.76036,     0.75072,     0.75072,     0.75072,     0.74644,     0.74644,     0.74644,     0.74644,     0.74644,     0.74366,     0.74366,     0.74366,     0.74302,     0.74302,     0.74302,     0.73757,     0.73757,     0.73425,     0.73425,     0.73171,     0.73171,     0.73171,\n",
              "            0.72606,     0.72606,     0.72606,     0.72606,     0.72606,     0.71916,     0.71318,     0.71318,     0.71318,     0.71318,     0.71208,       0.711,       0.711,     0.70677,     0.70677,     0.70677,     0.70677,     0.70677,     0.70677,     0.70574,     0.70574,     0.70123,     0.70123,\n",
              "            0.68182,     0.68095,     0.68095,     0.67213,     0.67133,     0.67133,      0.6659,      0.6659,     0.66514,     0.65548,     0.65548,     0.65548,     0.65548,     0.65548,     0.65044,     0.65044,     0.64551,     0.63931,     0.63931,     0.63753,     0.63753,     0.63753,     0.63753,\n",
              "            0.63753,      0.6263,     0.62578,     0.62578,     0.62474,     0.62474,     0.62474,     0.62423,     0.62423,     0.61943,     0.61943,     0.61943,     0.61895,     0.61895,     0.61477,     0.61431,     0.61431,     0.60784,     0.60784,     0.60659,     0.60659,     0.60659,     0.60659,\n",
              "            0.59924,     0.59924,     0.59886,     0.59886,     0.59811,     0.59811,     0.59811,     0.59774,     0.59774,     0.59626,     0.58932,     0.58932,     0.58545,     0.58545,     0.58545,     0.58303,     0.58303,     0.58111,     0.58111,     0.58111,     0.58111,     0.57672,     0.57672,\n",
              "            0.57043,     0.57043,      0.5692,     0.56701,     0.56701,     0.56581,     0.56581,     0.56155,     0.56155,     0.56155,      0.5604,     0.55281,     0.55281,     0.54992,     0.54992,     0.52904,     0.52812,     0.52812,      0.5264,     0.51745,     0.51745,     0.51745,     0.51745,\n",
              "            0.51506,     0.51493,     0.51493,     0.51493,     0.51493,     0.51493,     0.50882,     0.50882,     0.48873,     0.48607,     0.48607,     0.48607,     0.48607,     0.48481,     0.48481,     0.48481,     0.48422,     0.48422,     0.48422,     0.48098,     0.48098,     0.47844,     0.46904,\n",
              "            0.46904,     0.46859,     0.46859,     0.46859,     0.46442,     0.46442,     0.46036,     0.45987,     0.45987,     0.45765,     0.45765,      0.4566,     0.45614,     0.45614,      0.4484,      0.4484,     0.44364,     0.44058,     0.44058,      0.4372,      0.4372,      0.4372,     0.43581,\n",
              "            0.43581,     0.43357,     0.43357,     0.43357,     0.43121,     0.42989,     0.42989,     0.42955,     0.42955,     0.42922,     0.42793,     0.42793,     0.42793,     0.42793,     0.42793,     0.42793,     0.42793,     0.42428,     0.41567,     0.41567,      0.4107,      0.4107,      0.4107,\n",
              "            0.40569,     0.40569,     0.39794,     0.39734,     0.39734,     0.39734,     0.39734,     0.39734,     0.39514,     0.39514,     0.39257,     0.39257,     0.39044,     0.38872,     0.38872,     0.38068,     0.38054,     0.38054,     0.38004,     0.38004,      0.3799,     0.37761,     0.37761,\n",
              "            0.37642,     0.37244,     0.37244,     0.36823,     0.36823,     0.36512,     0.35569,     0.35569,     0.35532,     0.35532,     0.35526,      0.3406,      0.3406,     0.33973,     0.33803,     0.33803,     0.33552,     0.33552,     0.33552,     0.32261,     0.32261,     0.32238,     0.32165,\n",
              "            0.32165,     0.31676,     0.31676,     0.31655,     0.31491,     0.31491,     0.29325,     0.29325,     0.29028,     0.28936,     0.28936,     0.28926,     0.28504,     0.28504,     0.28456,     0.28456,     0.27976,     0.27931,     0.27931,      0.2788,      0.2788,      0.2788,     0.27232,\n",
              "            0.27232,     0.26952,     0.26416,     0.26416,     0.26332,     0.26332,     0.25855,     0.25577,     0.25577,     0.25381,     0.24843,     0.24843,      0.2459,      0.2459,     0.24577,     0.24427,     0.24427,      0.2432,      0.2432,     0.23615,     0.23467,     0.23467,     0.23284,\n",
              "            0.23178,     0.23178,     0.22946,     0.22946,     0.22946,     0.22867,     0.22867,     0.22743,     0.22085,     0.22085,     0.21972,     0.21972,      0.2187,     0.21344,     0.21344,     0.21344,     0.21344,     0.20791,     0.20723,     0.20723,      0.2045,     0.19817,     0.19817,\n",
              "            0.19715,     0.19715,     0.19447,     0.19244,     0.19244,     0.19077,     0.19071,     0.19071,     0.19034,     0.19034,     0.18796,     0.18632,     0.18632,     0.18575,     0.18575,     0.18482,     0.18426,     0.18426,     0.18415,     0.18203,     0.18203,     0.17921,     0.17921,\n",
              "            0.17564,      0.1749,      0.1749,     0.17359,     0.17269,     0.17269,     0.16481,     0.16481,     0.16289,     0.16092,     0.16092,     0.15826,     0.15826,     0.15184,     0.15168,     0.15168,     0.15123,     0.14837,     0.14837,     0.14615,     0.14615,     0.14444,      0.1426,\n",
              "             0.1426,     0.14244,     0.14244,     0.14161,     0.13812,     0.13812,     0.13507,     0.13482,     0.13482,     0.12452,     0.12452,     0.12005,     0.11813,     0.11813,     0.10907,     0.10864,     0.10864,     0.10002,     0.10002,    0.086744,    0.081156,    0.081156,    0.080989,\n",
              "           0.080989,     0.08098,    0.068804,    0.068804,    0.062963,    0.062632,    0.062301,    0.061969,    0.061638,    0.061306,    0.060975,    0.060644,    0.060312,    0.059981,     0.05965,    0.059318,    0.058987,    0.058655,    0.058324,    0.057993,    0.057661,     0.05733,    0.056998,\n",
              "           0.056667,    0.056336,    0.056004,    0.055673,    0.055342,     0.05501,    0.054679,    0.054347,    0.054016,    0.053685,    0.053353,    0.053022,     0.05269,    0.052359,    0.052028,    0.051696,    0.051365,    0.051033,    0.050702,    0.050371,    0.050039,    0.049708,    0.049377,\n",
              "           0.049045,    0.048714,    0.048382,    0.048051,     0.04772,    0.047388,    0.047057,    0.046725,    0.046394,    0.046063,    0.045731,      0.0454,    0.045069,    0.044737,    0.044406,    0.044074,    0.043743,    0.043412,     0.04308,    0.042749,    0.042417,    0.042086,    0.041755,\n",
              "           0.041423,    0.041092,    0.040761,    0.040429,    0.040098,    0.039766,    0.039435,    0.039104,    0.038772,    0.038441,    0.038109,    0.037778,    0.037447,    0.037115,    0.036784,    0.036452,    0.036121,     0.03579,    0.035458,    0.035127,    0.034796,    0.034464,    0.034133,\n",
              "           0.033801,     0.03347,    0.033139,    0.032807,    0.032476,    0.032144,    0.031813,    0.031482,     0.03115,    0.030819,    0.030488,    0.030156,    0.029825,    0.029493,    0.029162,    0.028831,    0.028499,    0.028168,    0.027836,    0.027505,    0.027174,    0.026842,    0.026511,\n",
              "            0.02618,    0.025848,    0.025517,    0.025185,    0.024854,    0.024523,    0.024191,     0.02386,    0.023528,    0.023197,    0.022866,    0.022534,    0.022203,    0.021871,     0.02154,    0.021209,    0.020877,    0.020546,    0.020215,    0.019883,    0.019552,     0.01922,    0.018889,\n",
              "           0.018558,    0.018226,    0.017895,    0.017563,    0.017232,    0.016901,    0.016569,    0.016238,    0.015907,    0.015575,    0.015244,    0.014912,    0.014581,     0.01425,    0.013918,    0.013587,    0.013255,    0.012924,    0.012593,    0.012261,     0.01193,    0.011599,    0.011267,\n",
              "           0.010936,    0.010604,    0.010273,   0.0099416,   0.0096102,   0.0092788,   0.0089474,    0.008616,   0.0082847,   0.0079533,   0.0076219,   0.0072905,   0.0069591,   0.0066277,   0.0062963,    0.005965,   0.0056336,   0.0053022,   0.0049708,   0.0046394,    0.004308,   0.0039766,   0.0036452,\n",
              "          0.0033139,   0.0029825,   0.0026511,   0.0023197,   0.0019883,   0.0016569,   0.0013255,  0.00099416,  0.00066277,  0.00033139,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.11726,     0.11726,     0.14699,     0.16516,     0.18165,     0.19451,     0.20561,     0.21523,     0.22396,     0.23046,     0.23673,     0.24255,      0.2489,     0.25405,     0.26024,     0.26573,     0.27085,     0.27569,     0.28154,       0.284,     0.28826,      0.2922,     0.29563,\n",
              "            0.29799,     0.30106,     0.30318,     0.30768,     0.31178,     0.31564,     0.31925,     0.32283,     0.32624,     0.32966,     0.33254,     0.33648,     0.33807,     0.34287,     0.34595,     0.34696,     0.34961,     0.35177,     0.35388,     0.35597,     0.35933,     0.36269,     0.36445,\n",
              "            0.36683,     0.36797,     0.37027,     0.37226,     0.37495,     0.37766,      0.3819,     0.38306,      0.3843,     0.38651,     0.38773,     0.38887,     0.39053,     0.39345,     0.39515,     0.39615,     0.39693,     0.39929,      0.4013,     0.40187,     0.40437,     0.40521,     0.40566,\n",
              "            0.40716,     0.40945,     0.41191,     0.41309,     0.41483,     0.41638,     0.41795,     0.41996,     0.42243,     0.42472,     0.42606,     0.42809,     0.42927,     0.43027,     0.43237,      0.4339,     0.43414,     0.43445,     0.43397,     0.43586,     0.43756,     0.44015,     0.44256,\n",
              "            0.44376,     0.44545,     0.44475,     0.44644,     0.44658,       0.448,     0.44777,     0.44949,     0.45042,     0.45306,     0.45467,     0.45549,     0.45632,     0.45682,     0.45761,     0.45844,     0.46016,      0.4599,     0.46048,     0.46171,     0.46356,     0.46411,     0.46538,\n",
              "            0.46627,     0.46693,      0.4692,     0.46962,     0.47026,     0.47104,     0.47215,     0.47238,     0.47319,     0.47355,     0.47501,     0.47519,     0.47571,     0.47588,     0.47725,     0.47677,     0.47631,     0.47639,     0.47718,     0.47828,     0.47949,     0.47987,     0.48077,\n",
              "            0.48186,     0.48319,     0.48279,     0.48353,     0.48371,      0.4841,     0.48476,     0.48597,     0.48688,      0.4856,     0.48586,     0.48611,     0.48677,     0.48753,     0.48867,     0.48956,     0.49128,      0.4908,     0.49201,      0.4936,      0.4945,     0.49353,     0.49434,\n",
              "            0.49474,     0.49566,     0.49656,     0.49621,      0.4966,     0.49756,       0.498,     0.49832,     0.49953,     0.50104,     0.50127,     0.50202,     0.50183,     0.50211,     0.50226,     0.50299,     0.50329,     0.50386,     0.50396,     0.50279,     0.50229,     0.50273,     0.50293,\n",
              "            0.50334,     0.50264,     0.50216,     0.50266,     0.50211,     0.50266,     0.50345,     0.50219,     0.50254,     0.50308,     0.50336,     0.50361,     0.50476,     0.50392,     0.50313,     0.50369,     0.50426,     0.50518,     0.50507,     0.50625,     0.50653,     0.50707,      0.5066,\n",
              "            0.50703,     0.50767,     0.50793,     0.50926,     0.50965,     0.51061,     0.51114,     0.51146,     0.51189,     0.51313,     0.51355,     0.51355,     0.51295,     0.51318,     0.51345,     0.51303,     0.51325,     0.51342,     0.51376,     0.51363,     0.51417,     0.51337,     0.51354,\n",
              "            0.51378,     0.51412,     0.51449,     0.51475,     0.51503,      0.5155,     0.51601,     0.51588,     0.51639,      0.5169,     0.51796,     0.51733,     0.51597,     0.51648,     0.51614,      0.5164,     0.51665,     0.51691,     0.51724,     0.51818,     0.51863,     0.52029,     0.52119,\n",
              "            0.52171,     0.52183,     0.52209,     0.52227,     0.52319,     0.52374,     0.52318,     0.52258,     0.52169,     0.52209,     0.52229,     0.52179,     0.52115,     0.52084,     0.52177,     0.52195,     0.52212,     0.52246,      0.5219,     0.52282,     0.52328,     0.52417,     0.52507,\n",
              "            0.52535,     0.52559,     0.52583,      0.5267,     0.52697,     0.52762,     0.52787,     0.52842,      0.5293,      0.5298,     0.53076,     0.53126,     0.53174,     0.53271,     0.53241,     0.53254,     0.53267,      0.5328,      0.5337,      0.5341,     0.53422,     0.53434,     0.53446,\n",
              "            0.53543,     0.53251,     0.53273,     0.53273,     0.53328,      0.5338,     0.53389,     0.53342,     0.53295,     0.53221,     0.53235,      0.5325,     0.53284,      0.5343,     0.53475,     0.53527,     0.53563,     0.53584,     0.53634,     0.53697,     0.53661,     0.53698,     0.53715,\n",
              "            0.53733,     0.53701,     0.53657,     0.53623,     0.53648,     0.53613,     0.53662,     0.53759,     0.53846,     0.53864,     0.53882,     0.53958,     0.54011,     0.54033,     0.54049,      0.5424,     0.54257,     0.54273,      0.5437,     0.54444,     0.54512,     0.54593,     0.54639,\n",
              "            0.54609,     0.54646,     0.54683,     0.54726,     0.54639,      0.5471,     0.54756,     0.54846,     0.54872,     0.54905,     0.54957,      0.5492,     0.54982,     0.54883,     0.54758,     0.54873,     0.54951,     0.54998,     0.54929,     0.54926,     0.54935,     0.54953,      0.5497,\n",
              "            0.54959,     0.54896,     0.54922,     0.54954,      0.5495,     0.54875,     0.54902,     0.54973,     0.54996,     0.55046,     0.55095,      0.5512,     0.55189,     0.55144,     0.55098,      0.5513,     0.55178,     0.55231,     0.55285,     0.55136,     0.55073,     0.55011,     0.55073,\n",
              "            0.55097,     0.55112,     0.54998,     0.55026,     0.55061,     0.55109,     0.54998,     0.54964,      0.5493,     0.54896,      0.5502,     0.55068,     0.55099,     0.55067,     0.55035,     0.55003,     0.55104,     0.55195,      0.5522,     0.55244,     0.55269,     0.55301,      0.5531,\n",
              "            0.55236,     0.55224,     0.55248,     0.55289,     0.55213,     0.55007,      0.5501,      0.5506,     0.54967,     0.54958,     0.54976,     0.54919,     0.55013,     0.55037,     0.55116,     0.55166,     0.55042,     0.54954,     0.54979,     0.54984,     0.54949,     0.54914,     0.54879,\n",
              "            0.54949,     0.54873,     0.54854,     0.54879,     0.54904,     0.54929,     0.55023,     0.55073,     0.55124,     0.55022,     0.55048,     0.55016,     0.55067,     0.55073,     0.55028,     0.54988,     0.55013,     0.55017,     0.54855,     0.54785,      0.5481,     0.54847,     0.54959,\n",
              "            0.54904,      0.5493,     0.54735,     0.54692,     0.54718,     0.54759,     0.54661,     0.54687,     0.54647,      0.5458,       0.546,      0.5462,      0.5463,      0.5464,      0.5465,     0.54661,     0.54685,      0.5471,      0.5486,     0.54938,     0.55013,     0.54945,     0.54748,\n",
              "            0.54774,     0.54792,     0.54746,       0.547,     0.54668,     0.54694,     0.54726,     0.54643,     0.54746,     0.54841,     0.54867,     0.54835,     0.54755,     0.54773,      0.5479,     0.54863,     0.54889,     0.54928,     0.54845,     0.54949,     0.54943,     0.54804,     0.54664,\n",
              "            0.54648,     0.54701,     0.54729,     0.54747,     0.54765,     0.54789,     0.54816,     0.54842,     0.54869,     0.54895,     0.54922,     0.54973,     0.55001,     0.55028,     0.54959,      0.5494,      0.5487,     0.54859,     0.54886,     0.54911,      0.5492,     0.54929,     0.54938,\n",
              "            0.54946,     0.54955,     0.54965,     0.54976,     0.54986,     0.54997,     0.55008,     0.54986,     0.54915,       0.549,     0.54815,     0.54961,     0.54988,     0.55007,     0.55021,     0.55035,     0.55048,     0.55001,     0.54923,     0.54917,     0.54995,     0.55009,     0.55023,\n",
              "            0.55036,     0.55137,     0.55192,     0.55277,     0.55304,     0.55327,     0.55349,     0.55387,     0.55429,     0.55456,     0.55484,     0.55512,     0.55436,     0.55416,     0.55472,     0.55447,     0.55213,      0.5512,     0.55046,     0.54917,     0.54985,      0.5501,     0.55029,\n",
              "            0.55048,      0.5506,     0.55011,     0.54962,     0.54989,     0.54962,     0.54935,     0.54908,     0.54882,     0.54888,     0.54916,     0.54829,     0.54681,     0.54649,     0.54668,     0.54686,     0.54734,      0.5476,     0.54779,     0.54798,     0.54849,     0.54743,     0.54844,\n",
              "            0.54887,     0.54916,     0.54854,     0.54598,     0.54522,     0.54562,      0.5459,     0.54636,     0.54466,     0.54442,     0.54495,     0.54454,     0.54349,     0.54377,     0.54414,     0.54471,     0.54304,     0.54207,      0.5398,     0.54018,     0.54048,     0.54076,     0.53924,\n",
              "            0.53847,     0.53765,     0.53628,     0.53692,     0.53752,     0.53781,     0.53685,     0.53638,     0.53674,     0.53703,     0.53739,     0.53742,     0.53663,     0.53556,     0.53481,     0.53385,     0.53434,     0.53472,     0.53166,     0.53218,     0.52911,      0.5294,     0.52976,\n",
              "             0.5277,     0.52609,     0.52271,     0.52235,     0.52199,     0.52163,     0.52152,     0.52255,     0.52278,     0.52301,     0.52194,     0.52262,      0.5232,     0.52346,     0.52369,     0.52409,     0.52452,     0.52482,     0.52516,     0.52547,     0.52492,     0.52437,     0.52381,\n",
              "            0.52315,     0.52249,     0.52273,     0.52362,     0.52386,     0.52206,     0.52096,     0.52128,     0.52187,     0.52444,     0.52468,     0.52464,     0.52427,      0.5239,     0.52353,     0.52319,     0.52343,     0.52367,     0.52352,     0.52315,     0.52278,     0.52241,     0.52222,\n",
              "            0.52261,     0.52244,     0.52211,     0.52177,     0.52144,      0.5211,     0.52031,     0.51947,     0.51758,     0.51753,     0.51685,     0.51289,     0.51312,     0.51336,     0.51214,       0.514,     0.51331,     0.51262,     0.51121,     0.51102,      0.5097,        0.51,     0.51115,\n",
              "            0.50994,     0.50869,      0.5073,     0.50675,     0.50621,     0.50551,     0.50316,     0.50249,     0.50285,     0.50235,     0.50184,     0.50134,     0.49951,     0.49808,     0.49689,      0.4943,     0.49358,      0.4929,      0.4923,     0.49171,     0.48969,     0.49008,     0.48856,\n",
              "            0.48411,     0.48151,     0.48088,     0.48042,     0.47997,     0.47955,     0.47993,     0.48032,     0.48072,     0.48138,     0.48149,     0.48103,     0.48057,     0.48011,     0.47977,     0.47947,     0.47916,     0.47885,     0.47855,     0.47824,      0.4726,     0.47207,     0.47154,\n",
              "            0.47101,     0.46913,     0.46672,      0.4656,     0.46607,      0.4656,     0.46513,     0.46467,     0.46393,      0.4627,     0.45703,     0.45573,     0.45611,     0.45499,     0.45536,     0.45248,     0.45021,     0.44924,      0.4486,     0.44796,      0.4466,     0.44707,     0.44233,\n",
              "            0.44208,     0.44222,     0.44236,     0.44249,      0.4419,     0.44093,     0.44034,     0.43967,     0.43931,     0.43866,       0.438,     0.43433,     0.43475,     0.43375,     0.43041,     0.42936,     0.42954,     0.42972,     0.42791,     0.42473,     0.42423,     0.42372,     0.42322,\n",
              "            0.41978,     0.41841,     0.41739,     0.41651,      0.4157,     0.41338,     0.41189,     0.41149,     0.40943,     0.40736,     0.40449,     0.40161,     0.40056,     0.39732,     0.39592,     0.39445,     0.39463,      0.3948,     0.39065,     0.38959,     0.38837,     0.38434,     0.38327,\n",
              "            0.38247,     0.38268,     0.38288,      0.3809,     0.38116,      0.3806,     0.37131,     0.36906,     0.36607,     0.36387,     0.36065,     0.35113,     0.34958,     0.34068,     0.33896,      0.3346,     0.33384,     0.33308,     0.33167,     0.32864,     0.32489,     0.32374,     0.31873,\n",
              "            0.31343,     0.31061,     0.30826,     0.30387,     0.29678,     0.28963,     0.28347,     0.27753,      0.2696,     0.26836,     0.26562,     0.26296,     0.25795,     0.25291,      0.2519,     0.24774,     0.24125,     0.24143,     0.23585,     0.23005,     0.22755,     0.22582,     0.22408,\n",
              "            0.21936,     0.21152,     0.20014,     0.19907,     0.19799,     0.19007,     0.18069,     0.17109,     0.16553,     0.16158,     0.15432,     0.14311,     0.13926,     0.12879,     0.12503,     0.11999,     0.10835,    0.097963,    0.096764,    0.095564,    0.092825,      0.0842,    0.075115,\n",
              "           0.064723,    0.062653,    0.058552,    0.053321,     0.04394,    0.039363,    0.034616,    0.031029,    0.024158,    0.021272,    0.018738,    0.018015,    0.017291,    0.016566,    0.014153,    0.012384,    0.011788,    0.011192,    0.010595,   0.0099981,   0.0093747,   0.0087172,   0.0080593,\n",
              "           0.007401,   0.0067422,    0.006042,   0.0053091,   0.0045755,   0.0038415,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.063211,    0.063211,    0.080869,    0.092074,     0.10247,     0.11079,     0.11809,     0.12452,     0.13044,     0.13497,     0.13934,     0.14355,      0.1482,     0.15205,      0.1565,     0.16064,     0.16446,     0.16812,      0.1725,      0.1746,     0.17792,     0.18103,     0.18385,\n",
              "            0.18598,     0.18859,     0.19057,     0.19425,     0.19777,       0.201,     0.20394,     0.20713,     0.21008,     0.21312,     0.21562,     0.21908,     0.22074,     0.22485,     0.22767,     0.22903,     0.23148,     0.23359,     0.23581,     0.23767,     0.24068,     0.24389,     0.24568,\n",
              "            0.24831,      0.2495,     0.25162,     0.25368,      0.2564,     0.25916,     0.26322,     0.26474,     0.26593,     0.26805,     0.26923,     0.27058,     0.27244,     0.27529,     0.27696,     0.27847,     0.27978,     0.28213,     0.28414,     0.28528,     0.28781,     0.28896,     0.29001,\n",
              "            0.29154,      0.2942,     0.29675,     0.29798,     0.29979,     0.30141,     0.30306,     0.30518,      0.3078,     0.31023,     0.31166,     0.31384,     0.31547,     0.31654,     0.31956,     0.32123,     0.32188,     0.32228,     0.32245,     0.32453,     0.32642,     0.32932,     0.33202,\n",
              "            0.33338,     0.33528,     0.33533,     0.33725,     0.33783,     0.33958,     0.34006,     0.34204,     0.34313,      0.3462,     0.34808,     0.34904,     0.35003,     0.35061,     0.35154,     0.35252,     0.35456,      0.3552,     0.35638,     0.35785,     0.36009,     0.36075,     0.36229,\n",
              "            0.36337,     0.36468,     0.36746,     0.36797,     0.36928,     0.37024,     0.37162,     0.37244,     0.37345,      0.3739,     0.37572,     0.37617,     0.37715,     0.37792,     0.37965,      0.3796,     0.38006,     0.38085,     0.38185,     0.38327,     0.38483,     0.38532,     0.38647,\n",
              "            0.38789,     0.39023,     0.39032,     0.39129,     0.39205,     0.39266,     0.39352,     0.39513,     0.39696,     0.39656,     0.39755,     0.39789,     0.39943,     0.40046,       0.402,     0.40321,     0.40563,     0.40558,     0.40724,     0.40942,     0.41065,     0.41073,     0.41186,\n",
              "            0.41241,     0.41369,     0.41495,      0.4152,     0.41574,     0.41709,     0.41771,     0.41815,     0.41987,     0.42201,     0.42233,      0.4234,     0.42389,     0.42429,      0.4245,     0.42554,     0.42598,      0.4268,     0.42773,     0.42779,     0.42768,     0.42833,     0.42862,\n",
              "            0.42921,     0.42901,     0.42912,     0.42987,     0.42951,     0.43097,     0.43266,     0.43234,       0.433,      0.4338,     0.43421,     0.43544,     0.43719,     0.43664,     0.43645,      0.4373,     0.43816,     0.43955,     0.44027,     0.44206,      0.4425,     0.44332,     0.44319,\n",
              "            0.44417,     0.44515,     0.44556,     0.44761,     0.44821,     0.45063,     0.45146,     0.45196,     0.45263,     0.45457,     0.45523,     0.45577,     0.45605,      0.4566,     0.45703,     0.45735,      0.4577,     0.45798,     0.45851,     0.45931,     0.46018,      0.4599,     0.46018,\n",
              "            0.46055,     0.46111,     0.46171,     0.46212,     0.46257,     0.46333,     0.46415,     0.46498,     0.46581,     0.46664,     0.46837,     0.46809,     0.46724,     0.46808,     0.46859,     0.46901,     0.46943,     0.46986,      0.4704,     0.47195,     0.47271,     0.47547,     0.47699,\n",
              "            0.47821,     0.47918,     0.47962,     0.48106,     0.48262,     0.48397,     0.48361,     0.48392,     0.48474,     0.48545,     0.48597,     0.48564,     0.48523,     0.48568,      0.4873,     0.48762,      0.4879,     0.48851,     0.48874,     0.49037,     0.49119,     0.49274,     0.49435,\n",
              "            0.49483,     0.49527,     0.49568,     0.49724,     0.49773,     0.49888,     0.49933,     0.50032,     0.50189,     0.50279,     0.50453,     0.50543,      0.5063,     0.50806,     0.50885,     0.50909,     0.50933,     0.50956,     0.51122,     0.51195,     0.51218,      0.5124,     0.51262,\n",
              "             0.5144,     0.51313,     0.51454,     0.51496,     0.51597,     0.51695,     0.51734,     0.51704,     0.51674,     0.51682,     0.51709,     0.51736,       0.518,     0.52078,     0.52163,     0.52263,      0.5233,     0.52372,     0.52466,     0.52588,     0.52667,     0.52739,     0.52772,\n",
              "            0.52806,      0.5279,     0.52763,     0.52745,     0.52793,     0.52878,     0.52972,     0.53163,     0.53334,     0.53368,     0.53403,     0.53553,     0.53658,     0.53702,     0.53734,     0.54112,     0.54145,     0.54177,      0.5437,      0.5452,     0.54656,      0.5482,     0.54912,\n",
              "            0.55018,     0.55092,     0.55166,     0.55254,     0.55245,     0.55391,     0.55485,      0.5567,     0.55724,     0.55793,     0.55901,     0.55996,     0.56125,     0.56085,     0.56008,     0.56252,     0.56416,     0.56514,      0.5655,     0.56656,     0.56747,     0.56783,      0.5682,\n",
              "            0.56885,     0.56846,     0.56903,     0.56973,      0.5702,     0.56988,     0.57046,       0.572,     0.57251,      0.5736,     0.57465,     0.57519,     0.57672,     0.57644,     0.57616,     0.57733,     0.57838,     0.57957,     0.58075,      0.5801,     0.57972,     0.58009,     0.58199,\n",
              "            0.58253,     0.58299,     0.58233,     0.58295,     0.58374,     0.58483,     0.58461,      0.5844,      0.5842,     0.58399,     0.58692,     0.58803,     0.58916,     0.58897,     0.58877,     0.58858,     0.59094,     0.59305,     0.59362,     0.59419,     0.59475,     0.59549,     0.59612,\n",
              "            0.59567,     0.59586,     0.59643,     0.59739,     0.59779,     0.59679,     0.59745,     0.59862,     0.59824,     0.59844,     0.59887,     0.59977,     0.60202,     0.60261,     0.60449,     0.60569,     0.60563,     0.60523,     0.60583,     0.60617,     0.60596,     0.60575,     0.60554,\n",
              "            0.60747,      0.6073,     0.60751,     0.60812,     0.60874,     0.60935,     0.61168,     0.61293,     0.61418,      0.6141,     0.61473,     0.61642,     0.61769,     0.61869,     0.61843,     0.61822,     0.61886,     0.61932,     0.61836,     0.61815,     0.61879,     0.61973,     0.62385,\n",
              "            0.62379,     0.62444,     0.62353,     0.62357,     0.62423,     0.62531,     0.62543,      0.6261,     0.62603,     0.62563,     0.62652,     0.62704,     0.62731,     0.62758,     0.62785,     0.62812,     0.62875,     0.62943,     0.63342,     0.63549,     0.63752,     0.63713,     0.63602,\n",
              "            0.63672,     0.63731,     0.63704,     0.63678,     0.63669,     0.63739,     0.63826,     0.63889,     0.64171,     0.64432,     0.64505,     0.64523,     0.64492,      0.6454,     0.64589,     0.64791,     0.64864,     0.64974,     0.65044,     0.65338,     0.65503,     0.65423,     0.65344,\n",
              "            0.65413,     0.65565,     0.65646,     0.65697,     0.65748,     0.65819,     0.65895,     0.65972,     0.66049,     0.66126,     0.66203,     0.66352,     0.66435,     0.66513,     0.66475,     0.66588,     0.66549,     0.66673,     0.66753,     0.66825,     0.66851,     0.66878,     0.66905,\n",
              "            0.66931,     0.66958,     0.66986,     0.67018,      0.6705,     0.67082,     0.67114,     0.67117,     0.67078,     0.67129,     0.67213,     0.67653,     0.67736,     0.67795,     0.67836,     0.67878,     0.67919,     0.68127,     0.68129,     0.68222,     0.68464,     0.68507,     0.68549,\n",
              "            0.68591,     0.68905,     0.69077,     0.69344,      0.6943,     0.69502,     0.69571,     0.69691,     0.69823,     0.69911,     0.69999,     0.70088,     0.70078,     0.70161,     0.70339,     0.70523,      0.7055,     0.70501,     0.70463,     0.70396,     0.70705,     0.70788,      0.7085,\n",
              "            0.70912,     0.71077,     0.71052,     0.71027,     0.71195,     0.71181,     0.71167,     0.71153,      0.7114,     0.71191,     0.71285,     0.71268,     0.71192,     0.71213,     0.71276,      0.7134,     0.71501,     0.71591,     0.71655,     0.71719,     0.71895,     0.71958,     0.72307,\n",
              "            0.72459,     0.72557,     0.72569,      0.7244,     0.72402,     0.72638,     0.72739,     0.72902,     0.73049,     0.73116,     0.73409,     0.73739,     0.73711,     0.73816,     0.73954,     0.74165,     0.74203,     0.74338,     0.74279,     0.74423,     0.74534,     0.74643,     0.74571,\n",
              "            0.74534,     0.74494,     0.74445,      0.7469,     0.74925,     0.75036,     0.75022,     0.75525,     0.75671,     0.75785,     0.75929,     0.76024,     0.75988,     0.75938,     0.75981,     0.76143,     0.76344,     0.76501,     0.76364,     0.76595,     0.76457,     0.76578,      0.7673,\n",
              "            0.76808,     0.76734,     0.76792,     0.76775,     0.76758,     0.76742,     0.76794,     0.77244,     0.77344,     0.77445,     0.77603,     0.78544,     0.78806,     0.78924,      0.7903,     0.79212,     0.79412,     0.79545,     0.79704,     0.79866,     0.79843,      0.7982,     0.79797,\n",
              "            0.79769,     0.79742,     0.79931,      0.8035,     0.80461,     0.80457,     0.80412,     0.80642,     0.80923,     0.82173,      0.8229,     0.82347,     0.82333,     0.82319,     0.82305,     0.82299,     0.82417,     0.82534,      0.8257,     0.82556,     0.82542,     0.82528,     0.82564,\n",
              "            0.82762,     0.82797,     0.82785,     0.82773,      0.8276,     0.82748,     0.82719,     0.82687,      0.8289,     0.83441,     0.83417,     0.83278,     0.83403,     0.83527,     0.83706,     0.84755,     0.84732,     0.84708,      0.8466,     0.84802,     0.84949,     0.85114,     0.85759,\n",
              "            0.85832,     0.85792,     0.85748,     0.85992,     0.86026,     0.86004,     0.86248,     0.86338,     0.86561,     0.86545,     0.86529,     0.86514,     0.86504,     0.86741,     0.86704,     0.86624,     0.86602,      0.8658,     0.86562,     0.86543,     0.86557,       0.868,     0.86783,\n",
              "            0.86643,     0.86561,     0.86541,     0.86526,     0.86512,     0.86509,     0.86759,     0.87011,     0.87278,     0.87715,     0.87974,     0.87961,     0.87948,     0.87934,     0.87924,     0.87915,     0.87906,     0.87898,     0.87889,      0.8788,     0.87713,     0.87697,     0.87681,\n",
              "            0.87665,     0.87609,     0.87535,     0.87527,     0.87891,     0.87877,     0.87863,     0.87849,     0.87827,     0.87958,     0.88005,     0.88036,     0.88316,     0.88821,     0.89108,     0.89069,     0.89006,     0.88979,     0.88961,     0.88943,     0.89316,     0.89754,     0.89627,\n",
              "            0.90114,     0.90229,     0.90345,      0.9046,     0.90484,      0.9046,     0.90889,     0.91208,     0.91315,       0.913,     0.91285,     0.91199,     0.92139,     0.92118,     0.92046,     0.92094,     0.92262,     0.92431,      0.9346,     0.93402,     0.93392,     0.93383,     0.93374,\n",
              "            0.93309,     0.93283,     0.93264,     0.93247,     0.93232,      0.9347,     0.93965,     0.94209,     0.94174,     0.94139,      0.9409,      0.9404,     0.94022,     0.93964,      0.9394,      0.9458,     0.94779,     0.94978,     0.94998,     0.94982,     0.94964,     0.94902,     0.94885,\n",
              "            0.94926,     0.95177,     0.95428,     0.95547,     0.95867,      0.9607,     0.95953,     0.96507,     0.96542,     0.96517,      0.9648,     0.96368,     0.96349,     0.96238,     0.96945,     0.96898,      0.9689,     0.96882,     0.96867,     0.96833,     0.96791,     0.96777,     0.97515,\n",
              "            0.97466,      0.9744,     0.97417,     0.97374,     0.97302,     0.97226,     0.97158,     0.97089,     0.96992,     0.96977,     0.97937,     0.97914,     0.97868,      0.9782,      0.9781,     0.97769,     0.98097,     0.98679,     0.98806,     0.98772,     0.98757,     0.98747,     0.98736,\n",
              "            0.98706,     0.98652,     0.98568,     0.98559,     0.98551,     0.98485,     0.98399,     0.98302,     0.98241,     0.98195,     0.98104,     0.97947,     0.97887,     0.97706,     0.97634,     0.97531,     0.97256,     0.96958,      0.9692,     0.96881,     0.96787,     0.96454,     0.96024,\n",
              "             0.9539,     0.95242,     0.94913,      0.9443,     0.93288,     0.92543,     0.91593,     0.90686,     0.88289,     0.86883,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.80906,     0.80906,     0.80583,     0.80097,     0.79935,     0.79612,      0.7945,     0.79288,     0.79126,     0.78803,     0.78641,     0.78155,      0.7767,     0.77184,     0.77184,     0.76861,     0.76699,     0.76537,     0.76537,     0.76052,      0.7589,     0.75728,     0.75405,\n",
              "            0.74919,     0.74595,      0.7411,     0.73948,     0.73625,     0.73463,     0.73463,     0.73139,     0.72977,      0.7275,     0.72654,     0.72492,     0.72168,     0.72168,     0.72006,     0.71521,     0.71401,     0.71197,     0.70874,     0.70874,     0.70874,     0.70712,      0.7055,\n",
              "            0.70181,     0.70065,     0.70065,     0.69903,     0.69741,     0.69579,     0.69545,     0.69256,     0.69256,     0.69256,     0.69256,     0.69094,     0.68932,     0.68932,     0.68932,     0.68608,     0.68285,     0.68285,     0.68285,     0.67961,     0.67961,     0.67799,     0.67476,\n",
              "            0.67476,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67314,     0.67152,     0.67152,     0.66828,     0.66828,     0.66667,     0.66638,     0.66343,     0.66343,     0.66343,     0.66343,     0.66343,\n",
              "            0.66343,     0.66343,     0.66019,     0.66019,     0.65858,     0.65812,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,      0.6521,     0.65049,     0.65049,     0.65049,     0.65049,     0.65049,\n",
              "            0.65049,     0.64887,     0.64887,     0.64887,     0.64725,     0.64725,     0.64725,     0.64563,     0.64563,     0.64563,     0.64563,     0.64497,     0.64401,     0.64239,     0.64239,     0.64078,     0.63785,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,\n",
              "            0.63592,      0.6343,     0.63269,     0.63269,      0.6313,     0.63107,     0.63107,     0.63104,     0.62945,     0.62621,      0.6246,      0.6246,     0.62298,     0.62298,     0.62298,     0.62298,     0.62281,     0.62136,     0.62136,     0.62136,     0.62136,     0.61812,     0.61812,\n",
              "            0.61812,     0.61812,     0.61812,      0.6165,      0.6165,      0.6165,      0.6165,      0.6165,      0.6165,      0.6165,      0.6165,      0.6165,     0.61489,     0.61489,     0.61489,     0.61489,     0.61489,     0.61489,     0.61327,      0.6097,     0.60841,     0.60841,     0.60841,\n",
              "            0.60841,      0.6068,     0.60518,     0.60513,     0.60425,     0.60297,     0.60194,     0.59895,     0.59871,     0.59871,     0.59871,     0.59709,     0.59705,     0.59572,     0.59385,     0.59385,     0.59385,     0.59385,     0.59223,     0.59223,     0.59223,     0.59223,     0.59117,\n",
              "            0.59061,     0.59061,     0.59061,     0.59061,     0.59061,       0.589,       0.589,       0.589,       0.589,       0.589,       0.589,     0.58811,     0.58607,     0.58576,     0.58576,     0.58414,     0.58414,     0.58414,     0.58414,     0.58252,     0.58252,     0.58091,     0.58091,\n",
              "            0.58091,     0.58091,     0.58091,     0.58091,     0.58091,     0.58091,     0.58091,     0.57929,     0.57929,     0.57929,     0.57929,     0.57814,     0.57605,     0.57605,     0.57443,     0.57443,     0.57443,     0.57443,     0.57443,     0.57443,     0.57443,     0.57443,     0.57443,\n",
              "            0.57391,     0.57282,     0.57282,      0.5712,      0.5712,     0.57063,      0.5698,     0.56796,     0.56472,     0.56472,     0.56449,     0.56375,     0.56282,     0.56149,     0.56149,     0.56149,     0.56149,     0.56149,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,\n",
              "            0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55987,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,\n",
              "            0.55825,      0.5534,     0.55225,     0.55178,     0.55178,     0.55178,     0.55153,     0.55087,     0.55021,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54854,     0.54693,     0.54693,     0.54693,\n",
              "            0.54693,     0.54644,     0.54583,     0.54531,     0.54531,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,\n",
              "            0.54207,     0.54207,     0.54207,     0.54207,     0.54045,     0.54045,     0.54045,     0.54045,     0.54045,     0.54045,     0.54045,     0.53883,     0.53883,     0.53731,     0.53562,      0.5356,      0.5356,      0.5356,     0.53398,     0.53299,     0.53236,     0.53236,     0.53236,\n",
              "            0.53159,     0.53076,     0.53074,     0.53074,     0.53024,     0.52913,     0.52913,     0.52913,     0.52913,     0.52913,     0.52913,     0.52913,     0.52912,     0.52852,     0.52791,     0.52751,     0.52751,     0.52751,     0.52751,     0.52534,     0.52451,     0.52308,     0.52265,\n",
              "            0.52265,     0.52256,     0.52104,     0.52104,     0.52104,     0.52104,     0.51923,     0.51879,     0.51835,      0.5179,      0.5178,      0.5178,     0.51746,     0.51705,     0.51663,     0.51622,     0.51618,     0.51618,     0.51618,     0.51618,     0.51618,     0.51618,     0.51587,\n",
              "            0.51492,     0.51456,     0.51456,     0.51456,     0.51294,     0.51014,     0.50971,     0.50971,      0.5084,     0.50809,     0.50809,     0.50647,     0.50647,     0.50647,     0.50647,     0.50647,     0.50443,     0.50324,     0.50324,     0.50309,     0.50265,     0.50221,     0.50176,\n",
              "            0.50162,     0.50047,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,     0.49838,     0.49838,     0.49676,     0.49676,     0.49622,     0.49567,     0.49515,     0.49515,     0.49491,      0.4929,     0.49191,     0.49191,     0.49191,     0.49112,\n",
              "            0.49029,     0.49029,     0.48776,     0.48706,     0.48706,     0.48706,     0.48544,     0.48544,     0.48486,     0.48403,     0.48382,     0.48382,     0.48382,     0.48382,     0.48382,     0.48382,     0.48382,     0.48382,     0.48382,     0.48382,     0.48381,     0.48298,     0.48058,\n",
              "            0.48058,     0.48052,     0.47997,     0.47942,     0.47896,     0.47896,     0.47896,     0.47735,     0.47735,     0.47735,     0.47735,     0.47676,     0.47573,     0.47573,     0.47573,     0.47573,     0.47573,     0.47573,     0.47411,     0.47411,     0.47316,      0.4715,     0.46984,\n",
              "            0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46926,     0.46844,     0.46761,     0.46678,     0.46602,     0.46602,     0.46602,     0.46602,     0.46602,     0.46602,\n",
              "            0.46602,     0.46602,     0.46602,     0.46602,     0.46602,     0.46602,     0.46602,     0.46568,     0.46486,      0.4644,     0.46278,     0.46278,     0.46278,     0.46278,     0.46278,     0.46278,     0.46278,     0.46117,     0.46005,     0.45955,     0.45955,     0.45955,     0.45955,\n",
              "            0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45955,     0.45855,     0.45793,     0.45793,     0.45681,     0.45354,     0.45248,     0.45165,     0.45018,     0.44984,     0.44984,     0.44984,\n",
              "            0.44984,     0.44934,     0.44879,     0.44824,     0.44793,     0.44763,     0.44733,     0.44702,     0.44672,      0.4466,      0.4466,     0.44553,     0.44387,     0.44337,     0.44337,     0.44337,     0.44337,     0.44337,     0.44337,     0.44337,     0.44337,     0.44175,     0.44175,\n",
              "            0.44175,     0.44175,     0.44091,     0.43807,     0.43725,     0.43689,     0.43689,     0.43689,      0.4342,     0.43366,     0.43331,     0.43165,     0.43042,     0.43042,     0.43042,     0.43042,     0.42821,     0.42655,     0.42395,     0.42395,     0.42395,     0.42395,     0.42232,\n",
              "            0.42149,     0.42061,     0.41909,     0.41909,     0.41909,     0.41909,     0.41798,     0.41586,     0.41586,     0.41586,     0.41586,      0.4156,     0.41477,     0.41365,     0.41262,       0.411,       0.411,       0.411,     0.40778,     0.40774,     0.40453,     0.40453,     0.40453,\n",
              "            0.40192,     0.40026,      0.3962,     0.39583,     0.39546,     0.39509,     0.39482,     0.39482,     0.39482,     0.39482,      0.3932,     0.39159,     0.39159,     0.39159,     0.39159,     0.39159,     0.39159,     0.39159,     0.39159,     0.39154,     0.39098,     0.39043,     0.38986,\n",
              "             0.3892,     0.38853,     0.38835,     0.38835,     0.38835,     0.38639,     0.38528,     0.38511,     0.38511,     0.38511,     0.38511,     0.38495,     0.38458,     0.38421,     0.38384,      0.3835,      0.3835,      0.3835,     0.38326,      0.3829,     0.38253,     0.38216,     0.38188,\n",
              "            0.38188,     0.38162,     0.38129,     0.38096,     0.38063,     0.38029,     0.37952,     0.37869,     0.37627,     0.37509,     0.37442,     0.37055,     0.37055,     0.37055,     0.36893,     0.36884,     0.36818,     0.36751,     0.36615,      0.3657,     0.36408,     0.36408,     0.36408,\n",
              "            0.36271,     0.36152,     0.36021,     0.35922,     0.35861,     0.35795,     0.35519,     0.35437,     0.35435,     0.35388,      0.3534,     0.35293,     0.35113,     0.34933,     0.34823,     0.34581,     0.34515,     0.34452,     0.34396,     0.34341,     0.34142,     0.34142,     0.33998,\n",
              "            0.33589,     0.33352,     0.33294,     0.33253,     0.33211,     0.33172,     0.33172,     0.33172,     0.33172,     0.33172,     0.33144,     0.33103,     0.33062,      0.3302,     0.32989,     0.32961,     0.32934,     0.32906,     0.32878,     0.32851,     0.32343,     0.32296,     0.32248,\n",
              "            0.32201,     0.32033,     0.31818,     0.31715,     0.31711,      0.3167,     0.31628,     0.31587,     0.31522,     0.31392,     0.30867,     0.30744,     0.30744,     0.30583,     0.30583,     0.30327,     0.30131,     0.30047,     0.29992,     0.29937,     0.29773,     0.29767,     0.29362,\n",
              "            0.29288,     0.29288,     0.29288,     0.29288,     0.29234,     0.29151,     0.29055,     0.28964,     0.28923,     0.28868,     0.28812,     0.28504,     0.28449,     0.28366,     0.28087,     0.27994,     0.27994,     0.27994,     0.27748,     0.27486,     0.27445,     0.27403,     0.27362,\n",
              "             0.2708,     0.26968,     0.26886,     0.26814,     0.26748,     0.26537,     0.26375,     0.26324,     0.26158,     0.25992,     0.25762,     0.25532,     0.25449,     0.25192,     0.25081,     0.24919,     0.24919,     0.24919,     0.24588,     0.24505,      0.2441,     0.24096,     0.24013,\n",
              "            0.23948,     0.23948,     0.23948,     0.23786,     0.23786,      0.2373,     0.23019,     0.22816,     0.22586,      0.2242,     0.22178,     0.21468,     0.21352,     0.20697,     0.20539,     0.20221,     0.20166,     0.20111,     0.20009,      0.1979,     0.19521,     0.19438,      0.1905,\n",
              "            0.18674,     0.18476,      0.1831,     0.18003,     0.17509,     0.17016,     0.16594,      0.1619,     0.15656,     0.15573,     0.15365,     0.15187,     0.14855,     0.14523,     0.14457,     0.14184,     0.13754,     0.13754,      0.1339,     0.13019,     0.12859,     0.12748,     0.12638,\n",
              "            0.12339,     0.11846,     0.11138,     0.11071,     0.11005,     0.10519,    0.099479,    0.093699,    0.090382,    0.088031,    0.083747,    0.077194,    0.074964,    0.068941,    0.066793,    0.063925,    0.057371,    0.051588,    0.050924,    0.050261,     0.04875,    0.044021,    0.039086,\n",
              "           0.033498,    0.032392,    0.030208,    0.027435,      0.0225,    0.020109,    0.017641,    0.015784,    0.012246,    0.010768,   0.0094579,   0.0090893,   0.0087207,   0.0083521,   0.0071269,   0.0062304,   0.0059288,   0.0056273,   0.0053257,   0.0050241,   0.0047094,   0.0043777,    0.004046,\n",
              "          0.0037142,   0.0033825,   0.0030302,   0.0026616,    0.002293,   0.0019244,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.3895286874002033)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.38953])\n",
              "names: {0: 'item'}\n",
              "nt_per_class: array([618])\n",
              "nt_per_image: array([197])\n",
              "results_dict: {'metrics/precision(B)': 0.5889662421471576, 'metrics/recall(B)': 0.5170468810234182, 'metrics/mAP50(B)': 0.5591717079111532, 'metrics/mAP50-95(B)': 0.3895286874002033, 'fitness': 0.3895286874002033}\n",
              "save_dir: PosixPath('/content/runs/detect/train2')\n",
              "speed: {'preprocess': 0.10781983750405288, 'inference': 0.7142656187454577, 'loss': 0.00043441562525003974, 'postprocess': 3.416450921872638}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"/content/drive/MyDrive/censorly-training/alcohol/finetune_with_all_neg/weights/best.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/censorly-training/alcohol/data_with_all_neg.yaml\",\n",
        "    epochs=12, imgsz=640, batch=-1,\n",
        "    lr0=0.002, lrf=0.01, cos_lr=True, patience=5,\n",
        "    # daha sakin augment\n",
        "    hsv_h=0.010, hsv_s=0.4, hsv_v=0.25,\n",
        "    mosaic=0.3, erasing=0.0, fliplr=0.5,\n",
        "    perspective=0.0003, mixup=0.0, copy_paste=0.0,\n",
        "    # loss ağırlıkları\n",
        "    box=7.5, dfl=1.5, cls=0.5,\n",
        "    deterministic=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECycyhJrdjJ2",
        "outputId": "6401d556-1292-4646-8da3-4bbad56de4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Fine-tune sonuçları Drive'a kopyalandı → /content/drive/MyDrive/censorly-training/alcohol/finetune_with_all_neg2\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# kaynak ve hedef\n",
        "src = Path(\"/content/runs/detect/train2\")\n",
        "dst = Path(\"/content/drive/MyDrive/censorly-training/alcohol/finetune_with_all_neg2\")\n",
        "\n",
        "# varsa önce silmek için (opsiyonel)\n",
        "if dst.exists():\n",
        "    shutil.rmtree(dst)\n",
        "\n",
        "# klasörü komple kopyala\n",
        "shutil.copytree(src, dst)\n",
        "\n",
        "print(f\"[OK] Fine-tune sonuçları Drive'a kopyalandı → {dst}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz50DogymoF0",
        "outputId": "3a0c1858-1834-4e5c-fa5c-bab64b5789c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Oluşturulan boş label sayısı: 0\n"
          ]
        }
      ],
      "source": [
        "# Bu hücre, False tarafında eksik boş .txt varsa üretir. Varsa atla.\n",
        "FALSE_LBL = Path(f\"{ROOT}/Alcohol-False/Alcohol-False/labels\")\n",
        "created = 0\n",
        "for split in [\"train\",\"validation\",\"test\"]:\n",
        "    img_dir = FALSE_IMG / split\n",
        "    lbl_dir = FALSE_LBL / split\n",
        "    if not img_dir.exists():\n",
        "        continue\n",
        "    lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for f in img_dir.rglob(\"*\"):\n",
        "        if f.is_file() and f.suffix.lower() in EXTS:\n",
        "            t = lbl_dir / (f.stem + \".txt\")\n",
        "            if not t.exists():\n",
        "                t.write_text(\"\")  # negatif -> boş label\n",
        "                created += 1\n",
        "print(\"Oluşturulan boş label sayısı:\", created)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Na0MVXag8r"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "ROOT  = f\"{DRIVE}/censorly-dataset/Alcohol\"\n",
        "\n",
        "TRUE2_IMG = Path(f\"{ROOT}/Alcohol-True/Edited-Alcohol-2/images\")\n",
        "TRUE2_LBL = Path(f\"{ROOT}/Alcohol-True/Edited-Alcohol-2/labels\")\n",
        "\n",
        "FALSE_IMG = Path(f\"{ROOT}/Alcohol-False/Alcohol-False/images\")\n",
        "FALSE_LBL = Path(f\"{ROOT}/Alcohol-False/Alcohol-False/labels\")\n",
        "\n",
        "EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veQpnq_paud7",
        "outputId": "bb529c51-1df8-441f-a4e8-be7c8193f5ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: true=1847 false=450 total=2297\n",
            "validation: true=231 false=123 total=354\n",
            "test: true=226 false=65 total=291\n",
            "wrote: /content/alcohol_lists/train.txt\n",
            "wrote: /content/alcohol_lists/validation.txt\n",
            "wrote: /content/alcohol_lists/test.txt\n"
          ]
        }
      ],
      "source": [
        "def list_images(base: Path, split: str):\n",
        "    p = base / split\n",
        "    if not p.exists(): return []\n",
        "    return [str(f.resolve()) for f in sorted(p.rglob(\"*\"))\n",
        "            if f.is_file() and f.suffix.lower() in EXTS]\n",
        "\n",
        "splits = {}\n",
        "for split in [\"train\",\"validation\",\"test\"]:\n",
        "    imgs_true  = list_images(TRUE2_IMG, split)\n",
        "    imgs_false = list_images(FALSE_IMG, split)\n",
        "    splits[split] = imgs_true + imgs_false\n",
        "    print(f\"{split}: true={len(imgs_true)} false={len(imgs_false)} total={len(splits[split])}\")\n",
        "\n",
        "# TXT dosyalarına yaz\n",
        "TXT_DIR = Path(\"/content/alcohol_lists\"); TXT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "paths = {}\n",
        "for split in [\"train\",\"validation\",\"test\"]:\n",
        "    p = TXT_DIR / f\"{split}.txt\"\n",
        "    p.write_text(\"\\n\".join(splits[split]))\n",
        "    paths[split] = str(p)\n",
        "    print(\"wrote:\", p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBkPndWCa8zW",
        "outputId": "c178f9dc-3e7f-4dac-a4ee-f84fb9d8f42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /content/alcohol_multi_plus_false_lists.yaml\n"
          ]
        }
      ],
      "source": [
        "DATA_YAML = \"/content/alcohol_multi_plus_false_lists.yaml\"\n",
        "\n",
        "names_block = [\n",
        " 'alcohol rack', 'beer bottle', 'beer can', 'beer glass',\n",
        " 'champagne bottle', 'champagne glass', 'cocktail',\n",
        " 'liquor bottle', 'liquor glass', 'vodka bottle', 'vodka glass',\n",
        " 'whiskey bottle', 'whiskey glass', 'white wine glass',\n",
        " 'wine bottle', 'wine glass'\n",
        "]\n",
        "\n",
        "data_yaml = f\"\"\"# Multiclass positives (Edited-Alcohol-2) + negatives (Alcohol-False) via TXT lists\n",
        "train: {paths['train']}\n",
        "val:   {paths['validation']}\n",
        "test:  {paths['test']}\n",
        "\n",
        "nc: 16\n",
        "names: {names_block}\n",
        "\"\"\"\n",
        "\n",
        "with open(DATA_YAML, \"w\") as f:\n",
        "    f.write(data_yaml)\n",
        "\n",
        "print(\"Wrote:\", DATA_YAML)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zYqiZtVbv1l",
        "outputId": "d6455f1d-a35d-4650-e7d8-24f01da0f145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.204)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=12, cls=0.5, compile=False, conf=None, copy_paste=0.05, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/alcohol_multi_plus_false_lists.yaml, degrees=7.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=80, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.7, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.55, multi_scale=False, name=scratch_multi_hardneg_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=30, perspective=0.0005, plots=True, pose=12.0, pretrained=True, profile=False, project=runs-alcohol, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs-alcohol/scratch_multi_hardneg_v1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=1.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 17.0MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=16\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3784960  ultralytics.nn.modules.head.Detect           [16, [192, 384, 576]]         \n",
            "Model summary: 169 layers, 25,865,584 parameters, 25,865,568 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 66.3MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 0.3±0.1 MB/s, size: 77.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/train... 2297 images, 451 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2297/2297 18.9it/s 2:01\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.2±0.4 ms, read: 0.3±0.2 MB/s, size: 80.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/validation... 354 images, 123 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 354/354 18.2it/s 19.5s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/validation.cache\n",
            "Plotting labels to /content/runs-alcohol/scratch_multi_hardneg_v1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs-alcohol/scratch_multi_hardneg_v1\u001b[0m\n",
            "Starting training for 80 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/80      24.6G      1.753      4.174      2.002         22       1280: 100% ━━━━━━━━━━━━ 144/144 2.5it/s 56.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.9it/s 4.1s\n",
            "                   all        354        665      0.551      0.208      0.117     0.0541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/80      22.6G      1.548      2.731      1.767         23       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 53.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.615      0.193      0.104     0.0405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/80      22.9G      1.631      2.658      1.843         45       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.201      0.149     0.0725     0.0318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/80      22.7G      1.728      2.847       1.93         41       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.541      0.158     0.0924     0.0406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/80      22.9G      1.758      2.802       1.96         31       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.668      0.115     0.0811     0.0357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/80      22.7G      1.751      2.783      1.966         53       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.71      0.121      0.115     0.0538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/80      22.7G      1.682      2.657      1.917         38       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.775      0.124      0.134     0.0629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/80      22.8G      1.696      2.654      1.914         17       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.684      0.169      0.142     0.0652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/80      22.8G      1.655      2.551      1.899         42       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.368      0.192      0.121     0.0581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/80      23.5G      1.628      2.496      1.854         26       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.571      0.154      0.127     0.0507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/80      22.8G      1.615      2.473      1.852         30       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.693      0.193      0.188     0.0949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/80      22.8G      1.623      2.422      1.847         42       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.625      0.249      0.198     0.0989\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/80      22.4G      1.583      2.369      1.816         37       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.429      0.253      0.197      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/80      23.2G      1.562      2.297      1.786         28       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.586      0.235      0.195     0.0999\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/80      22.8G      1.569       2.31      1.819         42       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.712      0.186      0.187     0.0957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/80      22.7G      1.548      2.278      1.776         30       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.559      0.207      0.194      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/80      22.6G      1.533      2.206      1.773         29       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.654      0.217      0.215      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/80      22.7G      1.516      2.166      1.758         42       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.666      0.228      0.197      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/80      22.6G      1.498      2.137      1.741         52       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.639      0.195      0.207      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/80      22.8G      1.501      2.091      1.729         61       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.498      0.247      0.226      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/80      22.4G      1.496      2.077      1.727         47       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.497      0.253      0.209       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/80      22.7G       1.46      1.997      1.697         59       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.561      0.231      0.235      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/80      22.8G      1.442      1.953      1.687         39       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.518      0.301      0.238      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/80      22.4G      1.451      1.992      1.705         24       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.483      0.302      0.274      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/80      22.3G      1.422      1.924       1.69         62       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.685      0.223      0.222       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/80      22.7G      1.414      1.917      1.668         29       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.311      0.399      0.271      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/80      22.8G      1.424      1.873      1.677         28       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.449      0.318      0.248      0.135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/80      22.7G      1.407      1.859      1.666         19       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665       0.34      0.305      0.246      0.132\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/80      22.8G      1.412      1.825      1.649         44       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.298      0.362      0.262      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/80      23.5G      1.401        1.8      1.642         32       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.655      0.237      0.239      0.128\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/80      22.7G      1.389      1.739      1.609         29       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.296      0.296      0.256      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/80      22.7G      1.377      1.724      1.607         33       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.544      0.209      0.262      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/80      22.7G      1.365      1.698      1.611         27       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.491      0.334      0.322       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/80      22.6G      1.343      1.667      1.593         17       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.469      0.363      0.282      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/80      22.6G      1.345       1.63      1.589         22       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.411      0.272      0.255      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/80      23.5G      1.344      1.645      1.593         58       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.278      0.298       0.24      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/80      22.6G      1.318        1.6       1.58         46       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.565      0.339      0.342      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/80      22.7G      1.316      1.574      1.579         30       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.316      0.354      0.277      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/80      22.8G      1.309      1.532      1.564         41       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.376      0.282      0.288      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/80      22.8G      1.299      1.496      1.543         43       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.455      0.276      0.289      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/80      22.7G      1.279       1.48       1.54         25       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.236      0.402       0.28      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/80      22.8G      1.281      1.441      1.535         54       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665       0.43      0.261      0.283      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/80      23.7G      1.251      1.415      1.521         38       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.302      0.325      0.275      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/80      22.6G      1.265      1.393      1.513         40       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.501      0.338      0.309      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/80      22.7G      1.242      1.353      1.509         18       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.397      0.282       0.26      0.147\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/80      22.7G      1.245      1.349      1.499         25       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.248      0.424      0.264      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/80      22.8G      1.239      1.325      1.507         23       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.431      0.265       0.28      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/80      23.1G      1.218      1.283      1.483         34       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.572      0.237      0.284      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/80      22.7G      1.232      1.262      1.485         63       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.231      0.383      0.279       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/80      22.7G      1.204       1.25      1.476         31       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.414      0.298       0.28      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      51/80      22.7G      1.188       1.22       1.46         41       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.525      0.333      0.329      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      52/80      22.9G      1.176      1.213      1.445         30       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.322       0.35      0.275      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      53/80      22.8G       1.18      1.205      1.448         39       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.439      0.318      0.302      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      54/80      22.7G      1.159      1.148      1.425         41       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.261      0.409      0.291      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      55/80      22.8G      1.157      1.141      1.412         21       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.349      0.325      0.278      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      56/80      23.4G      1.152      1.105      1.422         24       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.332      0.374      0.273      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      57/80      22.7G      1.143      1.087      1.423         65       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.272      0.424      0.326      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      58/80      22.7G       1.14      1.073      1.404         20       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665       0.27      0.395      0.323      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      59/80      22.7G      1.131      1.055      1.405         41       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.411      0.301      0.319      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      60/80      22.7G      1.108      1.014      1.376         34       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.426      0.319      0.306      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      61/80      22.8G      1.118      1.046      1.384         26       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.386      0.315      0.304      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      62/80      22.9G      1.102          1      1.372         39       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.377      0.302      0.281      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      63/80      22.6G       1.09     0.9654      1.364         46       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.271      0.421       0.32       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      64/80      22.7G      1.093     0.9804      1.376         14       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.287      0.331      0.302      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      65/80      22.9G      1.085     0.9603      1.372         26       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.294      0.368      0.309      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      66/80      22.7G      1.094     0.9559      1.356         19       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.278      0.393       0.31      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      67/80      22.9G       1.08     0.9273      1.354         19       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.291      0.372      0.306      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      68/80      22.8G       1.07     0.9256      1.349         47       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.344      0.334      0.304      0.186\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      69/80      22.6G      1.043     0.7275      1.287         26       1280: 100% ━━━━━━━━━━━━ 144/144 2.6it/s 55.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.257      0.353      0.295       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      70/80      22.7G      1.052     0.7186      1.299         17       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.28      0.352      0.294       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      71/80      22.7G      1.035     0.6976      1.284         17       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.306      0.309      0.305      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      72/80      22.8G      1.041     0.6938      1.276         15       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.316      0.327      0.308      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      73/80      22.6G      1.022     0.6754      1.275         16       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.245      0.409      0.297       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      74/80      22.6G      1.027     0.6836      1.269         22       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.255      0.405      0.301      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      75/80      22.6G      1.011     0.6583      1.262         29       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.293      0.333      0.304      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      76/80      22.7G      1.011     0.6619      1.254         19       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.339      0.294      0.295      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      77/80      22.6G      1.003     0.6609      1.252         89       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.275      0.369      0.299      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      78/80      22.8G      1.003     0.6473      1.257         10       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.315      0.292      0.302      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      79/80      22.6G      1.009     0.6562      1.259         57       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.312      0.293      0.306       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      80/80      22.8G      1.002     0.6579      1.248         12       1280: 100% ━━━━━━━━━━━━ 144/144 2.7it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.247      0.412      0.304      0.188\n",
            "\n",
            "80 epochs completed in 1.256 hours.\n",
            "Optimizer stripped from /content/runs-alcohol/scratch_multi_hardneg_v1/weights/last.pt, 52.1MB\n",
            "Optimizer stripped from /content/runs-alcohol/scratch_multi_hardneg_v1/weights/best.pt, 52.1MB\n",
            "\n",
            "Validating /content/runs-alcohol/scratch_multi_hardneg_v1/weights/best.pt...\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 92 layers, 25,849,024 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.8it/s 4.2s\n",
            "                   all        354        665      0.411        0.3      0.319      0.193\n",
            "          alcohol rack         10         31      0.147      0.129     0.0819     0.0399\n",
            "           beer bottle         18         22      0.362       0.93      0.757      0.474\n",
            "              beer can          6          6       0.63      0.297      0.596        0.4\n",
            "            beer glass         65         98      0.673      0.821      0.772      0.472\n",
            "      champagne bottle          7          7      0.253      0.286      0.161     0.0844\n",
            "       champagne glass         11         15      0.611      0.133      0.251      0.137\n",
            "              cocktail         85        121      0.792      0.669      0.789      0.483\n",
            "         liquor bottle          3          6          1          0     0.0551     0.0258\n",
            "          liquor glass          4          5          0          0     0.0211     0.0172\n",
            "           vodka glass          2          2          0          0     0.0735      0.039\n",
            "        whiskey bottle          1          1          0          0     0.0055     0.0011\n",
            "         whiskey glass          2          5      0.181        0.2     0.0989     0.0791\n",
            "      white wine glass         17         25      0.327       0.24      0.262      0.158\n",
            "           wine bottle         34        265      0.718      0.392       0.49      0.277\n",
            "            wine glass         25         56      0.477      0.407      0.373      0.207\n",
            "Speed: 0.4ms preprocess, 5.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs-alcohol/scratch_multi_hardneg_v1\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x78e731bfb7d0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  8.2694e-05,  4.1347e-05,           0],\n",
              "       [          1,           1,           1, ...,   0.0013888,  0.00069439,           0],\n",
              "       [          1,           1,           1, ...,    0.000462,    0.000231,           0],\n",
              "       ...,\n",
              "       [          1,           1,           1, ...,  0.00038585,  0.00019292,           0],\n",
              "       [          1,           1,           1, ...,  0.00071746,  0.00035873,           0],\n",
              "       [          1,           1,           1, ...,  0.00068158,  0.00034079,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.047525,    0.047525,    0.053541, ...,           0,           0,           0],\n",
              "       [   0.061047,    0.061047,    0.084661, ...,           0,           0,           0],\n",
              "       [   0.073529,    0.073529,     0.10461, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.05949,     0.05949,    0.079825, ...,           0,           0,           0],\n",
              "       [    0.18734,     0.18734,     0.21604, ...,           0,           0,           0],\n",
              "       [    0.10273,     0.10273,     0.13449, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.025316,    0.025316,    0.029193, ...,           1,           1,           1],\n",
              "       [   0.031532,    0.031532,    0.044295, ...,           1,           1,           1],\n",
              "       [   0.038462,    0.038462,    0.055806, ...,           1,           1,           1],\n",
              "       ...,\n",
              "       [   0.030837,    0.030837,    0.042009, ...,           1,           1,           1],\n",
              "       [    0.10819,     0.10819,     0.12805, ...,           1,           1,           1],\n",
              "       [   0.054715,    0.054715,    0.073243, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.3871,      0.3871,     0.32258, ...,           0,           0,           0],\n",
              "       [    0.95455,     0.95455,     0.95455, ...,           0,           0,           0],\n",
              "       [    0.83333,     0.83333,     0.83333, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [       0.84,        0.84,         0.8, ...,           0,           0,           0],\n",
              "       [    0.69811,     0.69811,     0.69057, ...,           0,           0,           0],\n",
              "       [    0.83929,     0.83929,     0.82143, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.19293737739074782)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([   0.039929,     0.47405,     0.40015,     0.47194,    0.084407,     0.13722,     0.48257,    0.025794,    0.017164,     0.19294,    0.038956,   0.0010994,    0.079129,     0.15822,     0.27686,     0.20657])\n",
              "names: {0: 'alcohol rack', 1: 'beer bottle', 2: 'beer can', 3: 'beer glass', 4: 'champagne bottle', 5: 'champagne glass', 6: 'cocktail', 7: 'liquor bottle', 8: 'liquor glass', 9: 'vodka bottle', 10: 'vodka glass', 11: 'whiskey bottle', 12: 'whiskey glass', 13: 'white wine glass', 14: 'wine bottle', 15: 'wine glass'}\n",
              "nt_per_class: array([ 31,  22,   6,  98,   7,  15, 121,   6,   5,   0,   2,   1,   5,  25, 265,  56])\n",
              "nt_per_image: array([10, 18,  6, 65,  7, 11, 85,  3,  4,  0,  2,  1,  2, 17, 34, 25])\n",
              "results_dict: {'metrics/precision(B)': 0.41143561824683594, 'metrics/recall(B)': 0.3003283217045466, 'metrics/mAP50(B)': 0.31913120840556414, 'metrics/mAP50-95(B)': 0.19293737739074782, 'fitness': 0.19293737739074782}\n",
              "save_dir: PosixPath('/content/runs-alcohol/scratch_multi_hardneg_v1')\n",
              "speed: {'preprocess': 0.40242212711705, 'inference': 4.951333316383859, 'loss': 0.00038607627714755237, 'postprocess': 1.5293286355853972}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -U ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Eski alkol ağırlıklarını kullanmıyoruz (bias taşımamak için), COCO ön-eğitimli backbone ile başlıyoruz\n",
        "model = YOLO('yolov8m.pt')   # hız için 'yolov8s.pt' de tercih edebilirsin\n",
        "\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=80,\n",
        "    imgsz=1280,              # küçük kadeh/etiket için faydalı\n",
        "    batch=16,\n",
        "    device=0,\n",
        "\n",
        "    # FP'yi bastırmaya yönelik:\n",
        "    lr0=0.01, lrf=0.01, weight_decay=0.0005,\n",
        "    optimizer='SGD',\n",
        "    cos_lr=True,             # daha stabil iniş\n",
        "\n",
        "    # Augment (abartmadan çeşitlilik):\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.7,\n",
        "    degrees=7.0, translate=0.05, scale=0.5, shear=1.0,\n",
        "    perspective=0.0005, flipud=0.0, fliplr=0.5,\n",
        "    mosaic=0.55, close_mosaic=12, mixup=0.0, copy_paste=0.05,\n",
        "\n",
        "    project=\"runs-alcohol\", name=\"scratch_multi_hardneg_v1\",\n",
        "    patience=30\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUkmYDpXvhGr",
        "outputId": "4fc72ab1-9480-4d71-99b2-db10a03c3ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': '/content/alcohol_bin_lists/train.txt', 'validation': '/content/alcohol_bin_lists/validation.txt', 'test': '/content/alcohol_bin_lists/test.txt'}\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "ROOT  = f\"{DRIVE}/censorly-dataset/Alcohol\"\n",
        "\n",
        "TRUE3_IMG = Path(f\"{ROOT}/Alcohol-True/Edited-Alcohol-3/images\")  # tek sınıf\n",
        "FALSE_IMG = Path(f\"{ROOT}/Alcohol-False/Alcohol-False/images\")    # negatif\n",
        "\n",
        "EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
        "\n",
        "def list_images(base: Path, split: str):\n",
        "    p = base / split\n",
        "    if not p.exists(): return []\n",
        "    return [str(f.resolve()) for f in sorted(p.rglob(\"*\")) if f.suffix.lower() in EXTS]\n",
        "\n",
        "splits = {}\n",
        "for split in [\"train\",\"validation\",\"test\"]:\n",
        "    splits[split] = list_images(TRUE3_IMG, split) + list_images(FALSE_IMG, split)\n",
        "\n",
        "from pathlib import Path\n",
        "TXT_DIR = Path(\"/content/alcohol_bin_lists\"); TXT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "paths = {}\n",
        "for s in [\"train\",\"validation\",\"test\"]:\n",
        "    p = TXT_DIR/f\"{s}.txt\"; p.write_text(\"\\n\".join(splits[s])); paths[s]=str(p)\n",
        "print(paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyVrwt-bUl_K",
        "outputId": "dddeaebb-7607-4a33-d5ed-aeab69074305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train pos 1847 neg 450 train_used 2522\n",
            "validation pos 231 neg 123 train_used 354\n",
            "test pos 226 neg 65 train_used 291\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "DRIVE=\"/content/drive/MyDrive\"; ROOT=f\"{DRIVE}/censorly-dataset/Alcohol\"\n",
        "TRUE_IMG=Path(f\"{ROOT}/Alcohol-True/Edited-Alcohol-2/images\")\n",
        "FALSE_IMG=Path(f\"{ROOT}/Alcohol-False/Alcohol-False/images\")\n",
        "EXTS={\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
        "\n",
        "def collect(p):\n",
        "    return [str(f.resolve()) for f in sorted(p.rglob(\"*\")) if f.suffix.lower() in EXTS]\n",
        "\n",
        "ratio_neg = 1.5  # negatifleri ~%50 daha fazla göster (FP’yi kırar)\n",
        "paths={}\n",
        "TXT_DIR=Path(\"/content/alcohol_multi_lists\"); TXT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "for split in [\"train\",\"validation\",\"test\"]:\n",
        "    pos = collect(TRUE_IMG/split)\n",
        "    neg = collect(FALSE_IMG/split)\n",
        "    overs = (neg * int(ratio_neg)) + neg[: int(len(neg)*(ratio_neg%1))]\n",
        "    allp = pos + overs if split==\"train\" else (pos + neg)\n",
        "    p = TXT_DIR/f\"{split}.txt\"; p.write_text(\"\\n\".join(allp)); paths[split]=str(p)\n",
        "    print(split, \"pos\",len(pos),\"neg\",len(neg),\"train_used\",len(allp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxhpnv3-U4_C",
        "outputId": "fb15d07d-0b19-4f24-ddfa-8aebd794e009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/alcohol_multi_plus_false.yaml\n"
          ]
        }
      ],
      "source": [
        "DATA_YAML=\"/content/alcohol_multi_plus_false.yaml\"\n",
        "names_block=[\n",
        " 'alcohol rack','beer bottle','beer can','beer glass',\n",
        " 'champagne bottle','champagne glass','cocktail',\n",
        " 'liquor bottle','liquor glass','vodka bottle','vodka glass',\n",
        " 'whiskey bottle','whiskey glass','white wine glass',\n",
        " 'wine bottle','wine glass'\n",
        "]\n",
        "open(DATA_YAML,\"w\").write(f\"\"\"\n",
        "train: {paths['train']}\n",
        "val:   {paths['validation']}\n",
        "test:  {paths['test']}\n",
        "nc: 16\n",
        "names: {names_block}\n",
        "\"\"\")\n",
        "print(DATA_YAML)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h69Gjys-VZFF",
        "outputId": "faee937f-9ab8-487e-d4cc-3ee463a9f29f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.199)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.204-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.204-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ultralytics\n",
            "  Attempting uninstall: ultralytics\n",
            "    Found existing installation: ultralytics 8.3.199\n",
            "    Uninstalling ultralytics-8.3.199:\n",
            "      Successfully uninstalled ultralytics-8.3.199\n",
            "Successfully installed ultralytics-8.3.204\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% ━━━━━━━━━━━━ 49.7MB 274.7MB/s 0.2s\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=12, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/alcohol_multi_plus_false.yaml, degrees=7.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.6, hsv_v=0.6, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=scratch_multi_hardneg_v2, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=40, perspective=0.0005, plots=True, pose=12.0, pretrained=True, profile=False, project=runs-alcohol, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs-alcohol/scratch_multi_hardneg_v2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=1.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 81.9MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=16\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3784960  ultralytics.nn.modules.head.Detect           [16, [192, 384, 576]]         \n",
            "Model summary: 169 layers, 25,865,584 parameters, 25,865,568 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 336.0MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 0.2±0.3 MB/s, size: 207.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/train... 2522 images, 676 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2522/2522 6.2it/s 6:49\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.0±0.6 ms, read: 0.1±0.1 MB/s, size: 80.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/validation... 354 images, 123 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 354/354 5.5it/s 1:05\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/censorly-dataset/Alcohol/Alcohol-False/Alcohol-False/labels/validation.cache\n",
            "Plotting labels to /content/runs-alcohol/scratch_multi_hardneg_v2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs-alcohol/scratch_multi_hardneg_v2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      24.4G      1.731      4.307      1.992         31       1280: 100% ━━━━━━━━━━━━ 158/158 2.6it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 3.0it/s 4.1s\n",
            "                   all        354        665      0.277      0.218     0.0843     0.0361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      22.9G      1.567      2.776      1.778         19       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 58.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.636      0.132      0.106      0.048\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      22.9G      1.673      2.756      1.868         21       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.614      0.112     0.0843     0.0391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      22.9G      1.774      2.904      1.967         21       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.764      0.104     0.0836     0.0339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      22.9G       1.77      2.879       1.97         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.557      0.157      0.103     0.0455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100        23G      1.742      2.756      1.967         19       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.662      0.115      0.115     0.0462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      22.9G      1.744      2.754      1.973         22       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.519      0.165      0.123     0.0577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      22.9G      1.726      2.674      1.953         30       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.572      0.172      0.134      0.058\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      22.8G      1.688      2.633      1.925         28       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.739      0.147      0.135     0.0676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      22.9G      1.701      2.619      1.917         58       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.751      0.126      0.155     0.0713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100        23G      1.662      2.535      1.885         37       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.69      0.171      0.163     0.0792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      22.8G      1.625      2.443      1.863         37       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.685      0.186      0.181     0.0857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      22.8G      1.599      2.383      1.842         48       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.645      0.205      0.131     0.0685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      22.9G      1.595      2.394      1.836         39       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.623       0.16       0.15     0.0731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      22.8G      1.601       2.38      1.859         44       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.73      0.185      0.164     0.0816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      22.8G      1.582      2.329      1.813         38       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665       0.53      0.185      0.147     0.0688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      22.7G      1.562       2.33      1.825         25       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.688      0.194      0.192      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      22.9G       1.54      2.243      1.791         21       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.609       0.22      0.195      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      22.9G      1.547      2.212      1.787         22       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.44       0.22      0.197      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      22.9G      1.512      2.165      1.764         22       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.643      0.229      0.206      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      22.8G      1.496       2.12      1.748         29       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.583      0.191      0.202      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      24.1G        1.5       2.08      1.749         39       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.607      0.225      0.208      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      22.7G      1.501      2.068      1.759         15       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.683      0.215      0.228      0.114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      22.8G      1.487      2.058      1.755         42       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.587      0.211      0.174     0.0885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      22.9G      1.464      2.003      1.709         27       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665       0.47      0.243      0.235      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100        23G      1.476      1.969      1.722         51       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.674      0.201      0.211      0.114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      22.8G      1.456      1.965      1.713         41       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.424      0.305      0.231      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      22.9G      1.432      1.945      1.703         44       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.558      0.251      0.244      0.132\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      22.7G      1.439      1.895      1.694         29       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.519      0.306      0.254      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      22.9G      1.425      1.886      1.687         35       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.638      0.237      0.226      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      22.7G      1.421      1.872      1.674         58       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.573      0.246       0.24      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      22.8G      1.403      1.814      1.666         14       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.629      0.227      0.229      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      22.8G      1.415      1.812      1.665         35       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.535      0.252      0.238      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      22.9G      1.389      1.803      1.644         31       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.537      0.271      0.233      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      22.5G      1.394      1.777       1.65         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.561      0.232      0.255      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      22.8G      1.376      1.709      1.634         40       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.464      0.312      0.253       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      24.1G      1.393      1.728      1.638         24       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.229      0.301      0.223      0.127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      22.8G      1.352      1.672      1.627         34       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.585      0.238      0.255      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      22.9G      1.341      1.671      1.613         27       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.478      0.226      0.245      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      22.8G      1.346      1.657      1.596         26       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.525      0.335        0.3      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      22.7G      1.321      1.572      1.585         24       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.384      0.279       0.25      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      22.9G      1.327      1.613      1.596         29       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665       0.47      0.308      0.273       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100      22.8G      1.327      1.549      1.599         27       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.423      0.257       0.24      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100        23G      1.305      1.519      1.569         37       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.345      0.305      0.259      0.147\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      22.9G      1.293       1.51      1.564         12       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.408      0.349      0.295      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      22.9G      1.291      1.484      1.555         19       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.543      0.296      0.295      0.155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100      22.9G      1.293      1.492       1.56         25       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.287      0.354      0.297      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      22.9G      1.281      1.468      1.542         34       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.336      0.357      0.293       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100      22.9G      1.281      1.436      1.535         43       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.282      0.379      0.273      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100      22.8G      1.255      1.391      1.515         20       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.289      0.373      0.291      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      22.8G      1.241      1.373      1.518         30       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.0it/s 3.0s\n",
            "                   all        354        665      0.377      0.302      0.247      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100        23G      1.234      1.339      1.502         46       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.314      0.364      0.282       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100      22.8G      1.234      1.349      1.507         35       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.309      0.404      0.311      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100        23G      1.236       1.31      1.503         35       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.341      0.373      0.291      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      22.8G      1.222      1.265      1.485         30       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.291      0.445      0.282      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      22.8G      1.232      1.272      1.487         44       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.352      0.289      0.293      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      22.5G      1.207      1.241      1.482         61       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.393      0.386      0.348      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      22.9G      1.194       1.21      1.463         22       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.296      0.392      0.296      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      22.8G      1.186      1.204      1.462         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 3.0s\n",
            "                   all        354        665      0.331       0.32      0.263      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      22.9G      1.189      1.233      1.456         43       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.312      0.332      0.276      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      22.8G      1.177      1.158      1.441         29       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.478      0.315      0.287      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      22.9G      1.168      1.113      1.431         24       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.353      0.332      0.293      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      22.7G      1.164      1.107      1.431         18       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.304      0.344      0.282      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100        23G      1.167      1.086      1.427         18       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.282      0.402      0.347      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      22.9G      1.133       1.09      1.426         28       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.275      0.395      0.294      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      22.9G      1.145      1.081      1.415         32       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.317      0.385      0.302      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      22.9G      1.115      1.025      1.405         15       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.271      0.328      0.267      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      22.7G      1.124      1.021      1.387         20       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.38      0.341      0.306      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      22.8G      1.109     0.9959      1.386         43       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.232      0.423      0.281      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100      23.2G       1.12      1.017      1.404         47       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.216      0.411      0.282       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      22.9G        1.1      0.999      1.382         29       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.272      0.405      0.317      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      23.1G      1.078     0.9416      1.372         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.392       0.33      0.314       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      22.9G      1.086     0.9519      1.368         48       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.279      0.418      0.359       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      22.9G      1.083      0.954      1.363         46       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.422      0.347      0.281      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100      23.8G      1.077      0.926      1.364         24       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.244       0.36      0.284      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100      22.8G      1.071     0.9092      1.366         54       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.291      0.349      0.292      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100      22.8G      1.083     0.9229      1.367         39       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.271      0.478      0.337      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100        23G      1.047     0.8825      1.333         43       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.259      0.432      0.361      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100      22.8G      1.052     0.8739      1.338         47       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.295      0.413      0.366      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100      22.8G      1.055     0.8924      1.338         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.369      0.348      0.318      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100      22.8G      1.035     0.8615      1.331         20       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.469      0.289      0.338      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100      22.8G       1.04     0.8539      1.327         43       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.335       0.39      0.363      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100      22.8G      1.024     0.8243      1.311         19       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.309      0.381      0.357      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100      22.9G      1.006     0.8315      1.309         29       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.308      0.404      0.362      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100      22.8G      1.021     0.8344      1.308         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665       0.29      0.401      0.367      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100        23G      1.021     0.8389      1.316         34       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.356      0.376      0.361      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100      22.8G      1.006     0.8081      1.307         45       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.325      0.371      0.364      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100      22.8G      1.009     0.8192      1.314         15       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.368      0.354      0.335      0.188\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100        23G     0.9753     0.6082      1.244         17       1280: 100% ━━━━━━━━━━━━ 158/158 2.6it/s 60.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.469      0.345      0.355      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100      22.9G     0.9678     0.5955      1.242          8       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665       0.32      0.374      0.342      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100      22.7G     0.9722     0.5922      1.229         23       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.308      0.419      0.366      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100      22.7G     0.9575     0.5814      1.231         22       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665       0.44      0.337       0.37       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100      22.7G     0.9497     0.5844      1.222         10       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.1it/s 2.9s\n",
            "                   all        354        665      0.428      0.349       0.37      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100        23G     0.9585     0.5775      1.208          8       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.445      0.335       0.36      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100      22.7G     0.9464     0.5757      1.213         16       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.342       0.36      0.355      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100      22.8G     0.9556     0.5726       1.22         15       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.362      0.351       0.35      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100      22.8G     0.9578     0.5699      1.222         41       1280: 100% ━━━━━━━━━━━━ 158/158 2.7it/s 57.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.8s\n",
            "                   all        354        665      0.367      0.365       0.35      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100      23.1G     0.9597     0.5724      1.212         10       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.345      0.359      0.354      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100      22.8G     0.9401     0.5637      1.208         31       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.3it/s 2.8s\n",
            "                   all        354        665      0.388      0.348      0.355      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100      22.9G     0.9397     0.5554      1.214         10       1280: 100% ━━━━━━━━━━━━ 158/158 2.8it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 4.2it/s 2.9s\n",
            "                   all        354        665      0.359      0.348      0.352      0.184\n",
            "\n",
            "100 epochs completed in 1.704 hours.\n",
            "Optimizer stripped from /content/runs-alcohol/scratch_multi_hardneg_v2/weights/last.pt, 52.1MB\n",
            "Optimizer stripped from /content/runs-alcohol/scratch_multi_hardneg_v2/weights/best.pt, 52.1MB\n",
            "\n",
            "Validating /content/runs-alcohol/scratch_multi_hardneg_v2/weights/best.pt...\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 92 layers, 25,849,024 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.9it/s 4.2s\n",
            "                   all        354        665       0.32      0.374      0.342      0.194\n",
            "          alcohol rack         10         31      0.134      0.129     0.0443     0.0233\n",
            "           beer bottle         18         22      0.398      0.818      0.779      0.477\n",
            "              beer can          6          6      0.503       0.17      0.616      0.355\n",
            "            beer glass         65         98       0.69      0.796      0.764      0.468\n",
            "      champagne bottle          7          7      0.115      0.429      0.102     0.0713\n",
            "       champagne glass         11         15      0.387      0.267      0.311       0.21\n",
            "              cocktail         85        121      0.821      0.702      0.796      0.531\n",
            "         liquor bottle          3          6      0.184      0.167      0.117     0.0627\n",
            "          liquor glass          4          5     0.0438     0.0701     0.0404     0.0283\n",
            "           vodka glass          2          2          0          0     0.0444     0.0253\n",
            "        whiskey bottle          1          1      0.113          1      0.497     0.0498\n",
            "         whiskey glass          2          5      0.111        0.2     0.0509     0.0458\n",
            "      white wine glass         17         25      0.356       0.28      0.289      0.182\n",
            "           wine bottle         34        265      0.586      0.302      0.397      0.218\n",
            "            wine glass         25         56      0.361      0.286      0.282      0.161\n",
            "Speed: 0.4ms preprocess, 4.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs-alcohol/scratch_multi_hardneg_v2\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7d1ada5143b0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.14286,     0.14286,     0.14286, ...,  8.3576e-05,  4.1788e-05,           0],\n",
              "       [          1,           1,           1, ...,   0.0022838,   0.0011419,           0],\n",
              "       [          1,           1,           1, ...,   0.0005315,  0.00026575,           0],\n",
              "       ...,\n",
              "       [          1,           1,           1, ...,  0.00049069,  0.00024534,           0],\n",
              "       [          1,           1,           1, ...,  0.00079813,  0.00039906,           0],\n",
              "       [          1,           1,           1, ...,  0.00097587,  0.00048794,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[      0.048,       0.048,    0.061956, ...,           0,           0,           0],\n",
              "       [   0.098361,    0.098361,     0.13352, ...,           0,           0,           0],\n",
              "       [   0.084034,    0.084034,     0.11686, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [     0.1092,      0.1092,     0.13185, ...,           0,           0,           0],\n",
              "       [    0.22656,     0.22656,     0.26054, ...,           0,           0,           0],\n",
              "       [    0.19725,     0.19725,     0.23186, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.025586,    0.025586,    0.033941, ...,           1,           1,           1],\n",
              "       [   0.051852,    0.051852,    0.071782, ...,           1,           1,           1],\n",
              "       [   0.044248,    0.044248,    0.062838, ...,           1,           1,           1],\n",
              "       ...,\n",
              "       [   0.058824,    0.058824,    0.072567, ...,           1,           1,           1],\n",
              "       [     0.1369,      0.1369,     0.16274, ...,           1,           1,           1],\n",
              "       [    0.11316,     0.11316,     0.13839, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.3871,      0.3871,     0.35484, ...,           0,           0,           0],\n",
              "       [    0.95455,     0.95455,     0.95455, ...,           0,           0,           0],\n",
              "       [    0.83333,     0.83333,     0.83333, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [       0.76,        0.76,        0.72, ...,           0,           0,           0],\n",
              "       [     0.6566,      0.6566,     0.65283, ...,           0,           0,           0],\n",
              "       [    0.76786,     0.76786,     0.71429, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.19393267065666947)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.02327,     0.47696,     0.35528,     0.46849,    0.071329,     0.21035,     0.53114,    0.062691,    0.028267,     0.19393,    0.025335,     0.04975,    0.045824,     0.18203,     0.21777,      0.1605])\n",
              "names: {0: 'alcohol rack', 1: 'beer bottle', 2: 'beer can', 3: 'beer glass', 4: 'champagne bottle', 5: 'champagne glass', 6: 'cocktail', 7: 'liquor bottle', 8: 'liquor glass', 9: 'vodka bottle', 10: 'vodka glass', 11: 'whiskey bottle', 12: 'whiskey glass', 13: 'white wine glass', 14: 'wine bottle', 15: 'wine glass'}\n",
              "nt_per_class: array([ 31,  22,   6,  98,   7,  15, 121,   6,   5,   0,   2,   1,   5,  25, 265,  56])\n",
              "nt_per_image: array([10, 18,  6, 65,  7, 11, 85,  3,  4,  0,  2,  1,  2, 17, 34, 25])\n",
              "results_dict: {'metrics/precision(B)': 0.32017495201694474, 'metrics/recall(B)': 0.3743335403897327, 'metrics/mAP50(B)': 0.341990472694057, 'metrics/mAP50-95(B)': 0.19393267065666947, 'fitness': 0.19393267065666947}\n",
              "save_dir: PosixPath('/content/runs-alcohol/scratch_multi_hardneg_v2')\n",
              "speed: {'preprocess': 0.39209737570482467, 'inference': 4.919785988703177, 'loss': 0.0003904745755409677, 'postprocess': 1.4418707966082993}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\") \n",
        "\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=100,\n",
        "    imgsz=1280,\n",
        "    batch=16,\n",
        "    device=0,\n",
        "\n",
        "    # FP'yi düşürmeye odak\n",
        "    lr0=0.01, lrf=0.01, weight_decay=0.0005,\n",
        "    optimizer=\"SGD\", cos_lr=True,\n",
        "\n",
        "    # Augment\n",
        "    mosaic=0.5, mixup=0.0, copy_paste=0.0,\n",
        "    hsv_h=0.015, hsv_s=0.6, hsv_v=0.6,\n",
        "    degrees=7.0, translate=0.05, scale=0.5, shear=1.0,\n",
        "    perspective=0.0005, flipud=0.0, fliplr=0.5,\n",
        "\n",
        "    close_mosaic=12,               # son 12 epoch mozaik kapalı \n",
        "    patience=40,\n",
        "\n",
        "    project=\"runs-alcohol\", name=\"scratch_multi_hardneg_v2\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
